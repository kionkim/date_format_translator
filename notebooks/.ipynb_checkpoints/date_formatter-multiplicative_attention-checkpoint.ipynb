{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import numpy as np\n",
    "import mxnet as mx\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "sys.path.append(\"../python/\")\n",
    "from date_format_translator_multiplicative_attention import *\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 1000\n",
    "N_train = int(N * .9)\n",
    "N_validation = N - N_train\n",
    "\n",
    "in_seq_len = 32\n",
    "out_seq_len = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "X, Y, Z, chars, char_indices, indices_char = generate_date_data(N)\n",
    "\n",
    "# create voca\n",
    "for i in range(N):\n",
    "    for t, char in enumerate(questions[i]):\n",
    "        X[i, t, char_indices[char]] = 1\n",
    "    for t, char in enumerate(answers[i]):\n",
    "        Y[i, t, char_indices[char]] = 1\n",
    "    for t, char in enumerate(answers_y[i]):\n",
    "        Z[i, t, char_indices[char]] = 1\n",
    "\n",
    "# train test split\n",
    "X_train, X_validation, Y_train, Y_validation, Z_train, Z_validation = \\\n",
    "    train_test_split(X, Y, Z, train_size=N_train)\n",
    "\n",
    "# Create dataloader\n",
    "tr_set = gluon.data.ArrayDataset(X_train, Y_train, Z_train)\n",
    "tr_data_iterator = gluon.data.DataLoader(tr_set, batch_size=256, shuffle=True)\n",
    "\n",
    "te_set =gluon.data.ArrayDataset(X_validation, Y_validation, Z_validation)\n",
    "te_data_iterator = gluon.data.DataLoader(te_set, batch_size=256, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define model, trainer and loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctx = mx.gpu()\n",
    "model = format_changer(300, in_seq_len, out_seq_len, len(chars), ctx)\n",
    "model.collect_params().initialize(mx.init.Xavier(), ctx = ctx)\n",
    "\n",
    "trainer = gluon.Trainer(model.collect_params(), 'rmsprop')\n",
    "loss = gluon.loss.SoftmaxCrossEntropyLoss(axis = 2, sparse_label = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[91m☒\u001b[0m 2002-September-04 Wed = 021(09/04/2002, wednesday) 0\n",
      "\u001b[91m☒\u001b[0m 2003-October-18 Sat = 0(10/18/2003, saturday) 0\n",
      "\u001b[91m☒\u001b[0m 2007-January-24 Wed = 0(01/24/2007, wednesday) 0\n",
      "\u001b[91m☒\u001b[0m 2012-April-10 Tue = 0(04/10/2012, tuesday) 0\n",
      "\u001b[91m☒\u001b[0m 2002-December-20 Fri = 2211(12/20/2002, friday) 0\n",
      "\u001b[91m☒\u001b[0m 2011-April-06 Wed = 0(04/06/2011, wednesday) 0\n",
      "\u001b[91m☒\u001b[0m 2008-August-06 Wed = 0(08/06/2008, wednesday) 0\n",
      "\u001b[91m☒\u001b[0m 2004-March-13 Sat = 0(03/13/2004, saturday) 0\n",
      "\u001b[91m☒\u001b[0m 2004-October-27 Wed = 021(10/27/2004, wednesday) 0\n",
      "\u001b[91m☒\u001b[0m 2004-July-04 Sun = 0(07/04/2004, sunday) 0\n",
      "Epoch 0. Train Loss: 2.2850785, Test Loss : 3.7005775\n",
      "Epoch 1. Train Loss: 0.8146172, Test Loss : 3.6420627\n",
      "Epoch 2. Train Loss: 0.59600973, Test Loss : 3.6152618\n",
      "Epoch 3. Train Loss: 0.46277297, Test Loss : 3.5493784\n",
      "Epoch 4. Train Loss: 0.41512313, Test Loss : 3.4835706\n",
      "Epoch 5. Train Loss: 0.42209235, Test Loss : 3.4399512\n",
      "Epoch 6. Train Loss: 0.33351013, Test Loss : 3.3488975\n",
      "Epoch 7. Train Loss: 0.33269083, Test Loss : 3.2743948\n",
      "Epoch 8. Train Loss: 0.2905662, Test Loss : 3.094466\n",
      "Epoch 9. Train Loss: 0.2827499, Test Loss : 2.9119754\n",
      "\u001b[91m☒\u001b[0m 2003-January-25 Sat = 03/2/0203, saturday(01/25/2003, saturday) 0\n",
      "\u001b[91m☒\u001b[0m 2005-February-23 Wed = 03/2/2003, wednesday(02/23/2005, wednesday) 0\n",
      "\u001b[91m☒\u001b[0m 2009-March-07 Sat = 003/10/2009, saturday(03/07/2009, saturday) 0\n",
      "\u001b[91m☒\u001b[0m 2003-December-26 Fri = 06/23/2026/2026, friday(12/26/2003, friday) 0\n",
      "\u001b[91m☒\u001b[0m 2008-February-09 Sat = 08/20/2008, saturday(02/09/2008, saturday) 0\n",
      "\u001b[91m☒\u001b[0m 2001-November-25 Sun = 01/2/2011, sunday(11/25/2001, sunday) 0\n",
      "\u001b[91m☒\u001b[0m 2011-April-16 Sat = 01/16/2011, saturday(04/16/2011, saturday) 0\n",
      "\u001b[91m☒\u001b[0m 2005-July-17 Sun = 07/17/2007, sunday(07/17/2005, sunday) 0\n",
      "\u001b[91m☒\u001b[0m 2012-June-11 Mon = 01/16/2011, monday(06/11/2012, monday) 0\n",
      "\u001b[91m☒\u001b[0m 2003-August-11 Mon = 01/3/10/2008, monday(08/11/2003, monday) 0\n",
      "Epoch 10. Train Loss: 0.27118528, Test Loss : 2.7652962\n",
      "Epoch 11. Train Loss: 0.23474444, Test Loss : 2.493196\n",
      "Epoch 12. Train Loss: 0.22751154, Test Loss : 2.1938152\n",
      "Epoch 13. Train Loss: 0.22151205, Test Loss : 1.8898162\n",
      "Epoch 14. Train Loss: 0.20964283, Test Loss : 1.6706766\n",
      "Epoch 15. Train Loss: 0.22477187, Test Loss : 1.1622103\n",
      "Epoch 16. Train Loss: 0.19337071, Test Loss : 0.75787824\n",
      "Epoch 17. Train Loss: 0.16979504, Test Loss : 0.5191726\n",
      "Epoch 18. Train Loss: 0.16217716, Test Loss : 0.4193801\n",
      "Epoch 19. Train Loss: 0.18560398, Test Loss : 0.2952341\n",
      "\u001b[91m☒\u001b[0m 2005-August-31 Wed = 08/30/2005, wednesday(08/31/2005, wednesday) 0\n",
      "\u001b[91m☒\u001b[0m 2008-June-27 Fri = 07/20/2007, friday(06/27/2008, friday) 0\n",
      "\u001b[91m☒\u001b[0m 2012-April-11 Wed = 04/11/2004, wednesday(04/11/2012, wednesday) 0\n",
      "\u001b[91m☒\u001b[0m 2010-November-07 Sun = 01/07/20007, sunday(11/07/2010, sunday) 0\n",
      "\u001b[91m☒\u001b[0m 2002-August-04 Sun = 00/28/004, sunday(08/04/2002, sunday) 0\n",
      "\u001b[91m☒\u001b[0m 2008-July-02 Wed = 00/27/2000, wednesday(07/02/2008, wednesday) 0\n",
      "\u001b[91m☒\u001b[0m 2009-November-14 Sat = 01/10/2004, saturday(11/14/2009, saturday) 0\n",
      "\u001b[91m☒\u001b[0m 2005-June-19 Sun = 06/09/2006, sunday(06/19/2005, sunday) 0\n",
      "\u001b[91m☒\u001b[0m 2010-June-04 Fri = 00/16/2000, friday(06/04/2010, friday) 0\n",
      "\u001b[91m☒\u001b[0m 2011-February-03 Thu = 01/20/2003, thursday(02/03/2011, thursday) 0\n",
      "Epoch 20. Train Loss: 0.1532754, Test Loss : 0.2850065\n",
      "Epoch 21. Train Loss: 0.1651092, Test Loss : 0.1915391\n",
      "Epoch 22. Train Loss: 0.12959343, Test Loss : 0.19913664\n",
      "Epoch 23. Train Loss: 0.15370628, Test Loss : 0.16560963\n",
      "Epoch 24. Train Loss: 0.14490396, Test Loss : 0.13420548\n",
      "Epoch 25. Train Loss: 0.11595062, Test Loss : 0.15339163\n",
      "Epoch 26. Train Loss: 0.12464012, Test Loss : 0.18572782\n",
      "Epoch 27. Train Loss: 0.119137004, Test Loss : 0.10765943\n",
      "Epoch 28. Train Loss: 0.102497876, Test Loss : 0.11706295\n",
      "Epoch 29. Train Loss: 0.118683934, Test Loss : 0.1459914\n",
      "\u001b[91m☒\u001b[0m 2007-December-25 Tue = 12/20/2005, tuesday(12/25/2007, tuesday) 0\n",
      "\u001b[91m☒\u001b[0m 2008-May-02 Fri = 05/20/2008, friday(05/02/2008, friday) 0\n",
      "\u001b[91m☒\u001b[0m 2006-May-06 Sat = 06/05/2006, saturday(05/06/2006, saturday) 0\n",
      "\u001b[91m☒\u001b[0m 2011-October-06 Thu = 01/16/2000, thursday(10/06/2011, thursday) 0\n",
      "\u001b[91m☒\u001b[0m 2006-November-19 Sun = 11/16/2009, sunday(11/19/2006, sunday) 0\n",
      "\u001b[92m☑\u001b[0m 2005-March-04 Fri = 03/04/2005, friday(03/04/2005, friday) 1\n",
      "\u001b[92m☑\u001b[0m 2008-December-08 Mon = 12/08/2008, monday(12/08/2008, monday) 1\n",
      "\u001b[91m☒\u001b[0m 2008-February-03 Sun = 02/08/2000, sunday(02/03/2008, sunday) 0\n",
      "\u001b[91m☒\u001b[0m 2012-September-02 Sun = 02/09/2002, sunday(09/02/2012, sunday) 0\n",
      "\u001b[91m☒\u001b[0m 2004-May-26 Wed = 05/24/2006, wednesday(05/26/2004, wednesday) 0\n",
      "Epoch 30. Train Loss: 0.11271878, Test Loss : 0.10484211\n",
      "Epoch 31. Train Loss: 0.09300332, Test Loss : 0.10325936\n",
      "Epoch 32. Train Loss: 0.09048273, Test Loss : 0.11058947\n",
      "Epoch 33. Train Loss: 0.0939975, Test Loss : 0.12939979\n",
      "Epoch 34. Train Loss: 0.092463546, Test Loss : 0.17128761\n",
      "Epoch 35. Train Loss: 0.10252441, Test Loss : 0.12465033\n",
      "Epoch 36. Train Loss: 0.07855988, Test Loss : 0.07738576\n",
      "Epoch 37. Train Loss: 0.06513624, Test Loss : 0.11818129\n",
      "Epoch 38. Train Loss: 0.0893439, Test Loss : 0.0962773\n",
      "Epoch 39. Train Loss: 0.07029775, Test Loss : 0.07170131\n",
      "\u001b[91m☒\u001b[0m 2005-June-01 Wed = 06/10/2002, wednesday(06/01/2005, wednesday) 0\n",
      "\u001b[92m☑\u001b[0m 2003-May-07 Wed = 05/07/2003, wednesday(05/07/2003, wednesday) 1\n",
      "\u001b[91m☒\u001b[0m 2004-September-05 Sun = 09/04/2005, sunday(09/05/2004, sunday) 0\n",
      "\u001b[91m☒\u001b[0m 2002-April-10 Wed = 04/10/20201, wednesday(04/10/2002, wednesday) 0\n",
      "\u001b[91m☒\u001b[0m 2010-April-11 Sun = 04/11/2011, sunday(04/11/2010, sunday) 0\n",
      "\u001b[92m☑\u001b[0m 2003-March-26 Wed = 03/26/2003, wednesday(03/26/2003, wednesday) 1\n",
      "\u001b[91m☒\u001b[0m 2012-August-19 Sun = 08/19/22011, sunday(08/19/2012, sunday) 0\n",
      "\u001b[92m☑\u001b[0m 2007-December-19 Wed = 12/19/2007, wednesday(12/19/2007, wednesday) 1\n",
      "\u001b[92m☑\u001b[0m 2007-April-16 Mon = 04/16/2007, monday(04/16/2007, monday) 1\n",
      "\u001b[92m☑\u001b[0m 2009-July-16 Thu = 07/16/2009, thursday(07/16/2009, thursday) 1\n",
      "Epoch 40. Train Loss: 0.058925595, Test Loss : 0.065297596\n",
      "Epoch 41. Train Loss: 0.06610032, Test Loss : 0.06564608\n",
      "Epoch 42. Train Loss: 0.05574224, Test Loss : 0.08871705\n",
      "Epoch 43. Train Loss: 0.07069341, Test Loss : 0.11248225\n",
      "Epoch 44. Train Loss: 0.08651508, Test Loss : 0.08656683\n",
      "Epoch 45. Train Loss: 0.058099188, Test Loss : 0.0495417\n",
      "Epoch 46. Train Loss: 0.03955479, Test Loss : 0.054489613\n",
      "Epoch 47. Train Loss: 0.06442121, Test Loss : 0.061280083\n",
      "Epoch 48. Train Loss: 0.043157265, Test Loss : 0.04520302\n",
      "Epoch 49. Train Loss: 0.059011973, Test Loss : 0.06952758\n",
      "\u001b[91m☒\u001b[0m 2011-October-10 Mon = 01/11/2010, monday(10/10/2011, monday) 0\n",
      "\u001b[91m☒\u001b[0m 2011-December-16 Fri = 12/16/2110, friday(12/16/2011, friday) 0\n",
      "\u001b[91m☒\u001b[0m 2006-December-13 Wed = 12/13/2010, wednesday(12/13/2006, wednesday) 0\n",
      "\u001b[91m☒\u001b[0m 2008-December-01 Mon = 10/12/2008, monday(12/01/2008, monday) 0\n",
      "\u001b[91m☒\u001b[0m 2003-November-26 Wed = 11/16/2002, wednesday(11/26/2003, wednesday) 0\n",
      "\u001b[91m☒\u001b[0m 2004-January-02 Fri = 01/02/2010, friday(01/02/2004, friday) 0\n",
      "\u001b[92m☑\u001b[0m 2004-July-19 Mon = 07/19/2004, monday(07/19/2004, monday) 1\n",
      "\u001b[91m☒\u001b[0m 2011-January-31 Mon = 01/13/2110, monday(01/31/2011, monday) 0\n",
      "\u001b[91m☒\u001b[0m 2009-June-23 Tue = 06/23/2010, tuesday(06/23/2009, tuesday) 0\n",
      "\u001b[91m☒\u001b[0m 2006-August-22 Tue = 08/20/22012, tuesday(08/22/2006, tuesday) 0\n",
      "Epoch 50. Train Loss: 0.04512405, Test Loss : 0.081594594\n",
      "Epoch 51. Train Loss: 0.068891264, Test Loss : 0.059932772\n",
      "Epoch 52. Train Loss: 0.03965898, Test Loss : 0.03534662\n",
      "Epoch 53. Train Loss: 0.029089035, Test Loss : 0.032235432\n",
      "Epoch 54. Train Loss: 0.02465279, Test Loss : 0.03175845\n",
      "Epoch 55. Train Loss: 0.04411313, Test Loss : 0.07285671\n",
      "Epoch 56. Train Loss: 0.0472395, Test Loss : 0.05133803\n",
      "Epoch 57. Train Loss: 0.028537808, Test Loss : 0.034818217\n",
      "Epoch 58. Train Loss: 0.03715036, Test Loss : 0.039918736\n",
      "Epoch 59. Train Loss: 0.03806974, Test Loss : 0.10579204\n",
      "\u001b[91m☒\u001b[0m 2009-June-13 Sat = 06/31/2009, saturday(06/13/2009, saturday) 0\n",
      "\u001b[92m☑\u001b[0m 2003-July-05 Sat = 07/05/2003, saturday(07/05/2003, saturday) 1\n",
      "\u001b[91m☒\u001b[0m 2001-November-02 Fri = 11/20/2010, friday(11/02/2001, friday) 0\n",
      "\u001b[92m☑\u001b[0m 2006-February-04 Sat = 02/04/2006, saturday(02/04/2006, saturday) 1\n",
      "\u001b[92m☑\u001b[0m 2007-September-28 Fri = 09/28/2007, friday(09/28/2007, friday) 1\n",
      "\u001b[92m☑\u001b[0m 2003-July-30 Wed = 07/30/2003, wednesday(07/30/2003, wednesday) 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m☑\u001b[0m 2006-February-22 Wed = 02/22/2006, wednesday(02/22/2006, wednesday) 1\n",
      "\u001b[91m☒\u001b[0m 2011-January-27 Thu = 07/12/2011, thursday(01/27/2011, thursday) 0\n",
      "\u001b[91m☒\u001b[0m 2008-October-26 Sun = 10/26/2008, saturday(10/26/2008, sunday) 0\n",
      "\u001b[91m☒\u001b[0m 2001-October-04 Thu = 01/04/2010, thursday(10/04/2001, thursday) 0\n",
      "Epoch 60. Train Loss: 0.049067914, Test Loss : 0.028744584\n",
      "Epoch 61. Train Loss: 0.025334591, Test Loss : 0.027239073\n",
      "Epoch 62. Train Loss: 0.02454345, Test Loss : 0.055509545\n",
      "Epoch 63. Train Loss: 0.028009351, Test Loss : 0.024691375\n",
      "Epoch 64. Train Loss: 0.017287795, Test Loss : 0.047478832\n",
      "Epoch 65. Train Loss: 0.08133365, Test Loss : 0.45040622\n",
      "Epoch 66. Train Loss: 0.059839286, Test Loss : 0.024376381\n",
      "Epoch 67. Train Loss: 0.014103169, Test Loss : 0.020507801\n",
      "Epoch 68. Train Loss: 0.014668925, Test Loss : 0.019526726\n",
      "Epoch 69. Train Loss: 0.012462708, Test Loss : 0.016772818\n",
      "\u001b[92m☑\u001b[0m 2008-April-16 Wed = 04/16/2008, wednesday(04/16/2008, wednesday) 1\n",
      "\u001b[92m☑\u001b[0m 2004-August-10 Tue = 08/10/2004, tuesday(08/10/2004, tuesday) 1\n",
      "\u001b[92m☑\u001b[0m 2004-May-09 Sun = 05/09/2004, sunday(05/09/2004, sunday) 1\n",
      "\u001b[92m☑\u001b[0m 2007-August-09 Thu = 08/09/2007, thursday(08/09/2007, thursday) 1\n",
      "\u001b[92m☑\u001b[0m 2008-May-30 Fri = 05/30/2008, friday(05/30/2008, friday) 1\n",
      "\u001b[92m☑\u001b[0m 2002-June-30 Sun = 06/30/2002, sunday(06/30/2002, sunday) 1\n",
      "\u001b[91m☒\u001b[0m 2004-April-02 Fri = 04/20/2004, friday(04/02/2004, friday) 0\n",
      "\u001b[91m☒\u001b[0m 2010-April-12 Mon = 04/12/2001, monday(04/12/2010, monday) 0\n",
      "\u001b[92m☑\u001b[0m 2006-August-27 Sun = 08/27/2006, sunday(08/27/2006, sunday) 1\n",
      "\u001b[91m☒\u001b[0m 2004-February-03 Tue = 02/30/2004, tuesday(02/03/2004, tuesday) 0\n",
      "Epoch 70. Train Loss: 0.01500427, Test Loss : 0.02932404\n",
      "Epoch 71. Train Loss: 0.030604158, Test Loss : 0.044476595\n",
      "Epoch 72. Train Loss: 0.022644997, Test Loss : 0.06144139\n",
      "Epoch 73. Train Loss: 0.041161194, Test Loss : 0.02277788\n",
      "Epoch 74. Train Loss: 0.014629448, Test Loss : 0.016724912\n",
      "Epoch 75. Train Loss: 0.013470908, Test Loss : 0.017436009\n",
      "Epoch 76. Train Loss: 0.013334293, Test Loss : 0.01729876\n",
      "Epoch 77. Train Loss: 0.018175397, Test Loss : 0.05289658\n",
      "Epoch 78. Train Loss: 0.035401113, Test Loss : 0.02817165\n",
      "Epoch 79. Train Loss: 0.016786147, Test Loss : 0.013899053\n",
      "\u001b[92m☑\u001b[0m 2003-September-08 Mon = 09/08/2003, monday(09/08/2003, monday) 1\n",
      "\u001b[91m☒\u001b[0m 2006-October-21 Sat = 10/12/2006, saturday(10/21/2006, saturday) 0\n",
      "\u001b[92m☑\u001b[0m 2009-June-24 Wed = 06/24/2009, wednesday(06/24/2009, wednesday) 1\n",
      "\u001b[92m☑\u001b[0m 2003-January-12 Sun = 01/12/2003, sunday(01/12/2003, sunday) 1\n",
      "\u001b[92m☑\u001b[0m 2004-September-26 Sun = 09/26/2004, sunday(09/26/2004, sunday) 1\n",
      "\u001b[92m☑\u001b[0m 2003-January-26 Sun = 01/26/2003, sunday(01/26/2003, sunday) 1\n",
      "\u001b[92m☑\u001b[0m 2004-March-17 Wed = 03/17/2004, wednesday(03/17/2004, wednesday) 1\n",
      "\u001b[92m☑\u001b[0m 2002-July-18 Thu = 07/18/2002, thursday(07/18/2002, thursday) 1\n",
      "\u001b[92m☑\u001b[0m 2004-February-26 Thu = 02/26/2004, thursday(02/26/2004, thursday) 1\n",
      "\u001b[91m☒\u001b[0m 2009-July-01 Wed = 07/10/2009, wednesday(07/01/2009, wednesday) 0\n",
      "Epoch 80. Train Loss: 0.011292916, Test Loss : 0.018374333\n",
      "Epoch 81. Train Loss: 0.015026695, Test Loss : 0.044696245\n",
      "Epoch 82. Train Loss: 0.021389566, Test Loss : 0.02278627\n",
      "Epoch 83. Train Loss: 0.027614143, Test Loss : 0.031967714\n",
      "Epoch 84. Train Loss: 0.014211007, Test Loss : 0.020975647\n",
      "Epoch 85. Train Loss: 0.010392061, Test Loss : 0.018065967\n",
      "Epoch 86. Train Loss: 0.011627169, Test Loss : 0.016188527\n",
      "Epoch 87. Train Loss: 0.016296174, Test Loss : 0.1641213\n",
      "Epoch 88. Train Loss: 0.037549574, Test Loss : 0.017553253\n",
      "Epoch 89. Train Loss: 0.013612935, Test Loss : 0.015842743\n",
      "\u001b[92m☑\u001b[0m 2003-May-15 Thu = 05/15/2003, thursday(05/15/2003, thursday) 1\n",
      "\u001b[92m☑\u001b[0m 2002-April-27 Sat = 04/27/2002, saturday(04/27/2002, saturday) 1\n",
      "\u001b[91m☒\u001b[0m 2005-July-30 Sat = 07/03/2005, saturday(07/30/2005, saturday) 0\n",
      "\u001b[92m☑\u001b[0m 2008-May-15 Thu = 05/15/2008, thursday(05/15/2008, thursday) 1\n",
      "\u001b[92m☑\u001b[0m 2007-February-07 Wed = 02/07/2007, wednesday(02/07/2007, wednesday) 1\n",
      "\u001b[92m☑\u001b[0m 2012-February-27 Mon = 02/27/2012, monday(02/27/2012, monday) 1\n",
      "\u001b[92m☑\u001b[0m 2010-September-29 Wed = 09/29/2010, wednesday(09/29/2010, wednesday) 1\n",
      "\u001b[92m☑\u001b[0m 2002-June-24 Mon = 06/24/2002, monday(06/24/2002, monday) 1\n",
      "\u001b[91m☒\u001b[0m 2001-September-12 Wed = 09/12/2010, wednesday(09/12/2001, wednesday) 0\n",
      "\u001b[92m☑\u001b[0m 2009-July-27 Mon = 07/27/2009, monday(07/27/2009, monday) 1\n",
      "Epoch 90. Train Loss: 0.009171887, Test Loss : 0.01626792\n",
      "Epoch 91. Train Loss: 0.00958926, Test Loss : 0.015342658\n",
      "Epoch 92. Train Loss: 0.010097499, Test Loss : 0.014178309\n",
      "Epoch 93. Train Loss: 0.010743139, Test Loss : 0.013519084\n",
      "Epoch 94. Train Loss: 0.008524617, Test Loss : 0.03307902\n",
      "Epoch 95. Train Loss: 0.03548445, Test Loss : 0.063002184\n",
      "Epoch 96. Train Loss: 0.012596513, Test Loss : 0.011113405\n",
      "Epoch 97. Train Loss: 0.007033378, Test Loss : 0.008062417\n",
      "Epoch 98. Train Loss: 0.00521795, Test Loss : 0.020507481\n",
      "Epoch 99. Train Loss: 0.007850772, Test Loss : 0.008176718\n",
      "\u001b[92m☑\u001b[0m 2010-May-14 Fri = 05/14/2010, friday(05/14/2010, friday) 1\n",
      "\u001b[92m☑\u001b[0m 2002-May-30 Thu = 05/30/2002, thursday(05/30/2002, thursday) 1\n",
      "\u001b[92m☑\u001b[0m 2004-July-15 Thu = 07/15/2004, thursday(07/15/2004, thursday) 1\n",
      "\u001b[92m☑\u001b[0m 2010-May-17 Mon = 05/17/2010, monday(05/17/2010, monday) 1\n",
      "\u001b[92m☑\u001b[0m 2009-July-04 Sat = 07/04/2009, saturday(07/04/2009, saturday) 1\n",
      "\u001b[92m☑\u001b[0m 2003-May-14 Wed = 05/14/2003, wednesday(05/14/2003, wednesday) 1\n",
      "\u001b[91m☒\u001b[0m 2009-October-13 Tue = 10/31/2009, tuesday(10/13/2009, tuesday) 0\n",
      "\u001b[92m☑\u001b[0m 2002-October-05 Sat = 10/05/2002, saturday(10/05/2002, saturday) 1\n",
      "\u001b[92m☑\u001b[0m 2003-July-23 Wed = 07/23/2003, wednesday(07/23/2003, wednesday) 1\n",
      "\u001b[92m☑\u001b[0m 2008-January-13 Sun = 01/13/2008, sunday(01/13/2008, sunday) 1\n",
      "Epoch 100. Train Loss: 0.0052539706, Test Loss : 0.024951583\n",
      "Epoch 101. Train Loss: 0.018342577, Test Loss : 0.06590281\n",
      "Epoch 102. Train Loss: 0.022157026, Test Loss : 0.012817533\n",
      "Epoch 103. Train Loss: 0.0058572255, Test Loss : 0.007326898\n",
      "Epoch 104. Train Loss: 0.0039817328, Test Loss : 0.0066866237\n",
      "Epoch 105. Train Loss: 0.0035934232, Test Loss : 0.010439775\n",
      "Epoch 106. Train Loss: 0.007164837, Test Loss : 0.014496633\n",
      "Epoch 107. Train Loss: 0.0081855655, Test Loss : 0.012103984\n",
      "Epoch 108. Train Loss: 0.008619124, Test Loss : 0.011464212\n",
      "Epoch 109. Train Loss: 0.0055828695, Test Loss : 0.009366671\n",
      "\u001b[91m☒\u001b[0m 2003-November-07 Fri = 11/27/003, friday(11/07/2003, friday) 0\n",
      "\u001b[91m☒\u001b[0m 2003-January-03 Fri = 01/30/2003, friday(01/03/2003, friday) 0\n",
      "\u001b[92m☑\u001b[0m 2008-April-28 Mon = 04/28/2008, monday(04/28/2008, monday) 1\n",
      "\u001b[92m☑\u001b[0m 2002-June-14 Fri = 06/14/2002, friday(06/14/2002, friday) 1\n",
      "\u001b[92m☑\u001b[0m 2004-February-18 Wed = 02/18/2004, wednesday(02/18/2004, wednesday) 1\n",
      "\u001b[91m☒\u001b[0m 2008-February-29 Fri = 02/29/008, friday(02/29/2008, friday) 0\n",
      "\u001b[92m☑\u001b[0m 2010-February-17 Wed = 02/17/2010, wednesday(02/17/2010, wednesday) 1\n",
      "\u001b[91m☒\u001b[0m 2005-September-24 Sat = 09/24/0005, saturday(09/24/2005, saturday) 0\n",
      "\u001b[92m☑\u001b[0m 2003-January-10 Fri = 01/10/2003, friday(01/10/2003, friday) 1\n",
      "\u001b[92m☑\u001b[0m 2008-January-26 Sat = 01/26/2008, saturday(01/26/2008, saturday) 1\n",
      "Epoch 110. Train Loss: 0.009926575, Test Loss : 0.027138975\n",
      "Epoch 111. Train Loss: 0.03536997, Test Loss : 0.053998314\n",
      "Epoch 112. Train Loss: 0.010422835, Test Loss : 0.006795851\n",
      "Epoch 113. Train Loss: 0.002751552, Test Loss : 0.005956845\n",
      "Epoch 114. Train Loss: 0.003168945, Test Loss : 0.005545201\n",
      "Epoch 115. Train Loss: 0.002343325, Test Loss : 0.005837926\n",
      "Epoch 116. Train Loss: 0.0020660192, Test Loss : 0.006351949\n",
      "Epoch 117. Train Loss: 0.004506168, Test Loss : 0.03520526\n",
      "Epoch 118. Train Loss: 0.014857608, Test Loss : 0.011072712\n",
      "Epoch 119. Train Loss: 0.012238624, Test Loss : 0.008956429\n",
      "\u001b[92m☑\u001b[0m 2007-January-27 Sat = 01/27/2007, saturday(01/27/2007, saturday) 1\n",
      "\u001b[92m☑\u001b[0m 2002-April-06 Sat = 04/06/2002, saturday(04/06/2002, saturday) 1\n",
      "\u001b[92m☑\u001b[0m 2004-November-13 Sat = 11/13/2004, saturday(11/13/2004, saturday) 1\n",
      "\u001b[92m☑\u001b[0m 2005-March-13 Sun = 03/13/2005, sunday(03/13/2005, sunday) 1\n",
      "\u001b[92m☑\u001b[0m 2002-June-19 Wed = 06/19/2002, wednesday(06/19/2002, wednesday) 1\n",
      "\u001b[92m☑\u001b[0m 2010-September-04 Sat = 09/04/2010, saturday(09/04/2010, saturday) 1\n",
      "\u001b[92m☑\u001b[0m 2005-June-01 Wed = 06/01/2005, wednesday(06/01/2005, wednesday) 1\n",
      "\u001b[92m☑\u001b[0m 2011-April-06 Wed = 04/06/2011, wednesday(04/06/2011, wednesday) 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m☑\u001b[0m 2008-July-17 Thu = 07/17/2008, thursday(07/17/2008, thursday) 1\n",
      "\u001b[92m☑\u001b[0m 2011-September-02 Fri = 09/02/2011, friday(09/02/2011, friday) 1\n",
      "Epoch 120. Train Loss: 0.0035952677, Test Loss : 0.004618361\n",
      "Epoch 121. Train Loss: 0.0021926756, Test Loss : 0.006486467\n",
      "Epoch 122. Train Loss: 0.0022317967, Test Loss : 0.008194125\n",
      "Epoch 123. Train Loss: 0.0024877577, Test Loss : 0.004022797\n",
      "Epoch 124. Train Loss: 0.0012265538, Test Loss : 0.0055931723\n",
      "Epoch 125. Train Loss: 0.0010743812, Test Loss : 0.0028312558\n",
      "Epoch 126. Train Loss: 0.0011772402, Test Loss : 0.021689976\n",
      "Epoch 127. Train Loss: 0.0506287, Test Loss : 0.20950755\n",
      "Epoch 128. Train Loss: 0.018877786, Test Loss : 0.012376925\n",
      "Epoch 129. Train Loss: 0.0033691232, Test Loss : 0.0059636747\n",
      "\u001b[92m☑\u001b[0m 2006-June-19 Mon = 06/19/2006, monday(06/19/2006, monday) 1\n",
      "\u001b[92m☑\u001b[0m 2011-March-15 Tue = 03/15/2011, tuesday(03/15/2011, tuesday) 1\n",
      "\u001b[92m☑\u001b[0m 2008-February-01 Fri = 02/01/2008, friday(02/01/2008, friday) 1\n",
      "\u001b[92m☑\u001b[0m 2009-October-10 Sat = 10/10/2009, saturday(10/10/2009, saturday) 1\n",
      "\u001b[92m☑\u001b[0m 2003-July-16 Wed = 07/16/2003, wednesday(07/16/2003, wednesday) 1\n",
      "\u001b[92m☑\u001b[0m 2008-July-10 Thu = 07/10/2008, thursday(07/10/2008, thursday) 1\n",
      "\u001b[92m☑\u001b[0m 2009-August-06 Thu = 08/06/2009, thursday(08/06/2009, thursday) 1\n",
      "\u001b[92m☑\u001b[0m 2009-April-14 Tue = 04/14/2009, tuesday(04/14/2009, tuesday) 1\n",
      "\u001b[92m☑\u001b[0m 2004-September-27 Mon = 09/27/2004, monday(09/27/2004, monday) 1\n",
      "\u001b[92m☑\u001b[0m 2005-July-06 Wed = 07/06/2005, wednesday(07/06/2005, wednesday) 1\n",
      "Epoch 130. Train Loss: 0.0023608282, Test Loss : 0.004140037\n",
      "Epoch 131. Train Loss: 0.0020705762, Test Loss : 0.0045824624\n",
      "Epoch 132. Train Loss: 0.0017452663, Test Loss : 0.0031495201\n",
      "Epoch 133. Train Loss: 0.0014585725, Test Loss : 0.0030872754\n",
      "Epoch 134. Train Loss: 0.0016575921, Test Loss : 0.0037126804\n",
      "Epoch 135. Train Loss: 0.0013294369, Test Loss : 0.002460151\n",
      "Epoch 136. Train Loss: 0.0011138623, Test Loss : 0.0027476784\n",
      "Epoch 137. Train Loss: 0.0008906374, Test Loss : 0.0018887386\n",
      "Epoch 138. Train Loss: 0.00078849157, Test Loss : 0.0014707758\n",
      "Epoch 139. Train Loss: 0.0007643145, Test Loss : 0.0020409087\n",
      "\u001b[92m☑\u001b[0m 2008-November-06 Thu = 11/06/2008, thursday(11/06/2008, thursday) 1\n",
      "\u001b[92m☑\u001b[0m 2006-December-24 Sun = 12/24/2006, sunday(12/24/2006, sunday) 1\n",
      "\u001b[92m☑\u001b[0m 2005-April-28 Thu = 04/28/2005, thursday(04/28/2005, thursday) 1\n",
      "\u001b[92m☑\u001b[0m 2007-April-25 Wed = 04/25/2007, wednesday(04/25/2007, wednesday) 1\n",
      "\u001b[92m☑\u001b[0m 2002-February-13 Wed = 02/13/2002, wednesday(02/13/2002, wednesday) 1\n",
      "\u001b[92m☑\u001b[0m 2010-May-31 Mon = 05/31/2010, monday(05/31/2010, monday) 1\n",
      "\u001b[92m☑\u001b[0m 2007-January-22 Mon = 01/22/2007, monday(01/22/2007, monday) 1\n",
      "\u001b[92m☑\u001b[0m 2002-August-20 Tue = 08/20/2002, tuesday(08/20/2002, tuesday) 1\n",
      "\u001b[92m☑\u001b[0m 2008-September-24 Wed = 09/24/2008, wednesday(09/24/2008, wednesday) 1\n",
      "\u001b[92m☑\u001b[0m 2006-March-24 Fri = 03/24/2006, friday(03/24/2006, friday) 1\n",
      "Epoch 140. Train Loss: 0.00083510415, Test Loss : 0.0015304451\n",
      "Epoch 141. Train Loss: 0.00071150274, Test Loss : 0.0023711242\n",
      "Epoch 142. Train Loss: 0.0009231521, Test Loss : 0.035352025\n",
      "Epoch 143. Train Loss: 0.0652944, Test Loss : 0.48810717\n",
      "Epoch 144. Train Loss: 0.03248922, Test Loss : 0.013139221\n",
      "Epoch 145. Train Loss: 0.001971246, Test Loss : 0.0046848957\n",
      "Epoch 146. Train Loss: 0.001499128, Test Loss : 0.0031983892\n",
      "Epoch 147. Train Loss: 0.0012154351, Test Loss : 0.0022547634\n",
      "Epoch 148. Train Loss: 0.0009683889, Test Loss : 0.0019653223\n",
      "Epoch 149. Train Loss: 0.00088687195, Test Loss : 0.0017705591\n",
      "\u001b[92m☑\u001b[0m 2011-January-08 Sat = 01/08/2011, saturday(01/08/2011, saturday) 1\n",
      "\u001b[92m☑\u001b[0m 2012-March-09 Fri = 03/09/2012, friday(03/09/2012, friday) 1\n",
      "\u001b[92m☑\u001b[0m 2006-February-11 Sat = 02/11/2006, saturday(02/11/2006, saturday) 1\n",
      "\u001b[92m☑\u001b[0m 2011-October-04 Tue = 10/04/2011, tuesday(10/04/2011, tuesday) 1\n",
      "\u001b[92m☑\u001b[0m 2009-July-07 Tue = 07/07/2009, tuesday(07/07/2009, tuesday) 1\n",
      "\u001b[92m☑\u001b[0m 2009-July-26 Sun = 07/26/2009, sunday(07/26/2009, sunday) 1\n",
      "\u001b[92m☑\u001b[0m 2011-December-30 Fri = 12/30/2011, friday(12/30/2011, friday) 1\n",
      "\u001b[92m☑\u001b[0m 2008-July-16 Wed = 07/16/2008, wednesday(07/16/2008, wednesday) 1\n",
      "\u001b[92m☑\u001b[0m 2004-March-03 Wed = 03/03/2004, wednesday(03/03/2004, wednesday) 1\n",
      "\u001b[92m☑\u001b[0m 2012-July-02 Mon = 07/02/2012, monday(07/02/2012, monday) 1\n",
      "Epoch 150. Train Loss: 0.00078571937, Test Loss : 0.0018767948\n",
      "Epoch 151. Train Loss: 0.00071784644, Test Loss : 0.0014320371\n",
      "Epoch 152. Train Loss: 0.00063357607, Test Loss : 0.0014296338\n",
      "Epoch 153. Train Loss: 0.00061279244, Test Loss : 0.0013776282\n",
      "Epoch 154. Train Loss: 0.00055841915, Test Loss : 0.0013776479\n",
      "Epoch 155. Train Loss: 0.0005446982, Test Loss : 0.001960956\n",
      "Epoch 156. Train Loss: 0.00072961184, Test Loss : 0.000997024\n",
      "Epoch 157. Train Loss: 0.00045898175, Test Loss : 0.0011331709\n",
      "Epoch 158. Train Loss: 0.00040283136, Test Loss : 0.001194566\n",
      "Epoch 159. Train Loss: 0.00038841274, Test Loss : 0.000999219\n",
      "\u001b[92m☑\u001b[0m 2003-May-11 Sun = 05/11/2003, sunday(05/11/2003, sunday) 1\n",
      "\u001b[92m☑\u001b[0m 2007-February-17 Sat = 02/17/2007, saturday(02/17/2007, saturday) 1\n",
      "\u001b[92m☑\u001b[0m 2011-October-12 Wed = 10/12/2011, wednesday(10/12/2011, wednesday) 1\n",
      "\u001b[92m☑\u001b[0m 2006-March-08 Wed = 03/08/2006, wednesday(03/08/2006, wednesday) 1\n",
      "\u001b[92m☑\u001b[0m 2004-June-27 Sun = 06/27/2004, sunday(06/27/2004, sunday) 1\n",
      "\u001b[92m☑\u001b[0m 2004-July-24 Sat = 07/24/2004, saturday(07/24/2004, saturday) 1\n",
      "\u001b[92m☑\u001b[0m 2006-July-20 Thu = 07/20/2006, thursday(07/20/2006, thursday) 1\n",
      "\u001b[92m☑\u001b[0m 2007-January-02 Tue = 01/02/2007, tuesday(01/02/2007, tuesday) 1\n",
      "\u001b[92m☑\u001b[0m 2001-December-22 Sat = 12/22/2001, saturday(12/22/2001, saturday) 1\n",
      "\u001b[92m☑\u001b[0m 2012-April-21 Sat = 04/21/2012, saturday(04/21/2012, saturday) 1\n",
      "Epoch 160. Train Loss: 0.00038375886, Test Loss : 0.00078624196\n",
      "Epoch 161. Train Loss: 0.00031252057, Test Loss : 0.0011057735\n",
      "Epoch 162. Train Loss: 0.00028645413, Test Loss : 0.0008384856\n",
      "Epoch 163. Train Loss: 0.00027524127, Test Loss : 0.0009758614\n",
      "Epoch 164. Train Loss: 0.00041017175, Test Loss : 0.005728877\n",
      "Epoch 165. Train Loss: 0.00043731026, Test Loss : 0.0014171143\n",
      "Epoch 166. Train Loss: 0.00028032792, Test Loss : 0.0006784461\n",
      "Epoch 167. Train Loss: 0.00025610306, Test Loss : 0.0012055954\n",
      "Epoch 168. Train Loss: 0.0793639, Test Loss : 4.318677\n",
      "Epoch 169. Train Loss: 0.057893354, Test Loss : 0.028868191\n",
      "\u001b[92m☑\u001b[0m 2002-December-30 Mon = 12/30/2002, monday(12/30/2002, monday) 1\n",
      "\u001b[92m☑\u001b[0m 2002-July-12 Fri = 07/12/2002, friday(07/12/2002, friday) 1\n",
      "\u001b[92m☑\u001b[0m 2008-July-17 Thu = 07/17/2008, thursday(07/17/2008, thursday) 1\n",
      "\u001b[92m☑\u001b[0m 2006-July-31 Mon = 07/31/2006, monday(07/31/2006, monday) 1\n",
      "\u001b[92m☑\u001b[0m 2007-February-26 Mon = 02/26/2007, monday(02/26/2007, monday) 1\n",
      "\u001b[92m☑\u001b[0m 2006-September-12 Tue = 09/12/2006, tuesday(09/12/2006, tuesday) 1\n",
      "\u001b[91m☒\u001b[0m 2007-January-20 Sat = 01/02/2007, saturday(01/20/2007, saturday) 0\n",
      "\u001b[92m☑\u001b[0m 2005-December-09 Fri = 12/09/2005, friday(12/09/2005, friday) 1\n",
      "\u001b[91m☒\u001b[0m 2002-January-20 Sun = 01/02/2002, sunday(01/20/2002, sunday) 0\n",
      "\u001b[92m☑\u001b[0m 2008-May-31 Sat = 05/31/2008, saturday(05/31/2008, saturday) 1\n",
      "Epoch 170. Train Loss: 0.0023364641, Test Loss : 0.008849855\n",
      "Epoch 171. Train Loss: 0.001429661, Test Loss : 0.0040766066\n",
      "Epoch 172. Train Loss: 0.0010802578, Test Loss : 0.0026239443\n",
      "Epoch 173. Train Loss: 0.0008523711, Test Loss : 0.002166529\n",
      "Epoch 174. Train Loss: 0.00071761874, Test Loss : 0.0018171855\n",
      "Epoch 175. Train Loss: 0.00062937464, Test Loss : 0.0015720938\n",
      "Epoch 176. Train Loss: 0.000569214, Test Loss : 0.0013809454\n",
      "Epoch 177. Train Loss: 0.0005017244, Test Loss : 0.0011899814\n",
      "Epoch 178. Train Loss: 0.00042802663, Test Loss : 0.0010344561\n",
      "Epoch 179. Train Loss: 0.0003856386, Test Loss : 0.0009257892\n",
      "\u001b[92m☑\u001b[0m 2011-February-12 Sat = 02/12/2011, saturday(02/12/2011, saturday) 1\n",
      "\u001b[92m☑\u001b[0m 2008-April-11 Fri = 04/11/2008, friday(04/11/2008, friday) 1\n",
      "\u001b[92m☑\u001b[0m 2012-February-20 Mon = 02/20/2012, monday(02/20/2012, monday) 1\n",
      "\u001b[92m☑\u001b[0m 2010-June-30 Wed = 06/30/2010, wednesday(06/30/2010, wednesday) 1\n",
      "\u001b[92m☑\u001b[0m 2006-May-29 Mon = 05/29/2006, monday(05/29/2006, monday) 1\n",
      "\u001b[92m☑\u001b[0m 2009-April-18 Sat = 04/18/2009, saturday(04/18/2009, saturday) 1\n",
      "\u001b[92m☑\u001b[0m 2009-December-28 Mon = 12/28/2009, monday(12/28/2009, monday) 1\n",
      "\u001b[92m☑\u001b[0m 2001-October-18 Thu = 10/18/2001, thursday(10/18/2001, thursday) 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m☑\u001b[0m 2011-October-14 Fri = 10/14/2011, friday(10/14/2011, friday) 1\n",
      "\u001b[92m☑\u001b[0m 2012-September-19 Wed = 09/19/2012, wednesday(09/19/2012, wednesday) 1\n",
      "Epoch 180. Train Loss: 0.0003658055, Test Loss : 0.00083815545\n",
      "Epoch 181. Train Loss: 0.00033256522, Test Loss : 0.0008212298\n",
      "Epoch 182. Train Loss: 0.00030117258, Test Loss : 0.00076499773\n",
      "Epoch 183. Train Loss: 0.00029620327, Test Loss : 0.0007248221\n",
      "Epoch 184. Train Loss: 0.00026118438, Test Loss : 0.0006518106\n",
      "Epoch 185. Train Loss: 0.00025870156, Test Loss : 0.00083058485\n",
      "Epoch 186. Train Loss: 0.00024050049, Test Loss : 0.0006595467\n",
      "Epoch 187. Train Loss: 0.0002144266, Test Loss : 0.0007905736\n",
      "Epoch 188. Train Loss: 0.0002324937, Test Loss : 0.0005099992\n",
      "Epoch 189. Train Loss: 0.00020910708, Test Loss : 0.0005323132\n",
      "\u001b[92m☑\u001b[0m 2003-January-17 Fri = 01/17/2003, friday(01/17/2003, friday) 1\n",
      "\u001b[92m☑\u001b[0m 2009-September-18 Fri = 09/18/2009, friday(09/18/2009, friday) 1\n",
      "\u001b[92m☑\u001b[0m 2005-September-03 Sat = 09/03/2005, saturday(09/03/2005, saturday) 1\n",
      "\u001b[92m☑\u001b[0m 2006-February-04 Sat = 02/04/2006, saturday(02/04/2006, saturday) 1\n",
      "\u001b[92m☑\u001b[0m 2002-February-18 Mon = 02/18/2002, monday(02/18/2002, monday) 1\n",
      "\u001b[92m☑\u001b[0m 2003-January-23 Thu = 01/23/2003, thursday(01/23/2003, thursday) 1\n",
      "\u001b[92m☑\u001b[0m 2007-February-18 Sun = 02/18/2007, sunday(02/18/2007, sunday) 1\n",
      "\u001b[92m☑\u001b[0m 2003-June-02 Mon = 06/02/2003, monday(06/02/2003, monday) 1\n",
      "\u001b[92m☑\u001b[0m 2002-November-26 Tue = 11/26/2002, tuesday(11/26/2002, tuesday) 1\n",
      "\u001b[92m☑\u001b[0m 2002-June-04 Tue = 06/04/2002, tuesday(06/04/2002, tuesday) 1\n",
      "Epoch 190. Train Loss: 0.00018930016, Test Loss : 0.00057021243\n",
      "Epoch 191. Train Loss: 0.00018023522, Test Loss : 0.0005528317\n",
      "Epoch 192. Train Loss: 0.00016509148, Test Loss : 0.00039797605\n",
      "Epoch 193. Train Loss: 0.00015043211, Test Loss : 0.0004119179\n",
      "Epoch 194. Train Loss: 0.00014423647, Test Loss : 0.00042326207\n",
      "Epoch 195. Train Loss: 0.00015108165, Test Loss : 0.00041587773\n",
      "Epoch 196. Train Loss: 0.00014203037, Test Loss : 0.00060225837\n",
      "Epoch 197. Train Loss: 0.0003145295, Test Loss : 0.14634131\n",
      "Epoch 198. Train Loss: 0.05562472, Test Loss : 0.013279593\n",
      "Epoch 199. Train Loss: 0.0009566052, Test Loss : 0.0024816864\n",
      "\u001b[92m☑\u001b[0m 2003-November-08 Sat = 11/08/2003, saturday(11/08/2003, saturday) 1\n",
      "\u001b[92m☑\u001b[0m 2003-January-31 Fri = 01/31/2003, friday(01/31/2003, friday) 1\n",
      "\u001b[92m☑\u001b[0m 2009-October-31 Sat = 10/31/2009, saturday(10/31/2009, saturday) 1\n",
      "\u001b[92m☑\u001b[0m 2011-May-27 Fri = 05/27/2011, friday(05/27/2011, friday) 1\n",
      "\u001b[92m☑\u001b[0m 2001-November-03 Sat = 11/03/2001, saturday(11/03/2001, saturday) 1\n",
      "\u001b[92m☑\u001b[0m 2006-September-11 Mon = 09/11/2006, monday(09/11/2006, monday) 1\n",
      "\u001b[92m☑\u001b[0m 2005-June-15 Wed = 06/15/2005, wednesday(06/15/2005, wednesday) 1\n",
      "\u001b[92m☑\u001b[0m 2010-September-30 Thu = 09/30/2010, thursday(09/30/2010, thursday) 1\n",
      "\u001b[92m☑\u001b[0m 2009-June-20 Sat = 06/20/2009, saturday(06/20/2009, saturday) 1\n",
      "\u001b[92m☑\u001b[0m 2009-November-18 Wed = 11/18/2009, wednesday(11/18/2009, wednesday) 1\n",
      "Epoch 200. Train Loss: 0.00046939374, Test Loss : 0.0014010865\n",
      "Epoch 201. Train Loss: 0.00037282368, Test Loss : 0.001193409\n",
      "Epoch 202. Train Loss: 0.0003051297, Test Loss : 0.0009399319\n",
      "Epoch 203. Train Loss: 0.00027747982, Test Loss : 0.0009414307\n",
      "Epoch 204. Train Loss: 0.00026528226, Test Loss : 0.00053778704\n",
      "Epoch 205. Train Loss: 0.0002490079, Test Loss : 0.00062141725\n",
      "Epoch 206. Train Loss: 0.00020345047, Test Loss : 0.0004948377\n",
      "Epoch 207. Train Loss: 0.00021606442, Test Loss : 0.00058975106\n",
      "Epoch 208. Train Loss: 0.00020115335, Test Loss : 0.0004785625\n",
      "Epoch 209. Train Loss: 0.00016887538, Test Loss : 0.00036802347\n",
      "\u001b[92m☑\u001b[0m 2006-July-04 Tue = 07/04/2006, tuesday(07/04/2006, tuesday) 1\n",
      "\u001b[92m☑\u001b[0m 2003-July-16 Wed = 07/16/2003, wednesday(07/16/2003, wednesday) 1\n",
      "\u001b[92m☑\u001b[0m 2011-April-12 Tue = 04/12/2011, tuesday(04/12/2011, tuesday) 1\n",
      "\u001b[92m☑\u001b[0m 2002-May-15 Wed = 05/15/2002, wednesday(05/15/2002, wednesday) 1\n",
      "\u001b[92m☑\u001b[0m 2009-March-19 Thu = 03/19/2009, thursday(03/19/2009, thursday) 1\n",
      "\u001b[92m☑\u001b[0m 2012-May-17 Thu = 05/17/2012, thursday(05/17/2012, thursday) 1\n",
      "\u001b[92m☑\u001b[0m 2011-April-30 Sat = 04/30/2011, saturday(04/30/2011, saturday) 1\n",
      "\u001b[92m☑\u001b[0m 2008-December-18 Thu = 12/18/2008, thursday(12/18/2008, thursday) 1\n",
      "\u001b[92m☑\u001b[0m 2012-January-20 Fri = 01/20/2012, friday(01/20/2012, friday) 1\n",
      "\u001b[92m☑\u001b[0m 2002-May-01 Wed = 05/01/2002, wednesday(05/01/2002, wednesday) 1\n",
      "Epoch 210. Train Loss: 0.00017440887, Test Loss : 0.0004070375\n",
      "Epoch 211. Train Loss: 0.00014776614, Test Loss : 0.00036844678\n",
      "Epoch 212. Train Loss: 0.00013951564, Test Loss : 0.00036209458\n",
      "Epoch 213. Train Loss: 0.00012729949, Test Loss : 0.00034800838\n",
      "Epoch 214. Train Loss: 0.00013169194, Test Loss : 0.00029826502\n",
      "Epoch 215. Train Loss: 0.0001272431, Test Loss : 0.00028867373\n",
      "Epoch 216. Train Loss: 0.00011629351, Test Loss : 0.0004252249\n",
      "Epoch 217. Train Loss: 0.000108689586, Test Loss : 0.00023772693\n",
      "Epoch 218. Train Loss: 0.000115791525, Test Loss : 0.0002408341\n",
      "Epoch 219. Train Loss: 0.00010388906, Test Loss : 0.0002571746\n",
      "\u001b[92m☑\u001b[0m 2010-April-25 Sun = 04/25/2010, sunday(04/25/2010, sunday) 1\n",
      "\u001b[92m☑\u001b[0m 2011-August-27 Sat = 08/27/2011, saturday(08/27/2011, saturday) 1\n",
      "\u001b[92m☑\u001b[0m 2011-September-09 Fri = 09/09/2011, friday(09/09/2011, friday) 1\n",
      "\u001b[92m☑\u001b[0m 2008-August-07 Thu = 08/07/2008, thursday(08/07/2008, thursday) 1\n",
      "\u001b[92m☑\u001b[0m 2011-November-08 Tue = 11/08/2011, tuesday(11/08/2011, tuesday) 1\n",
      "\u001b[92m☑\u001b[0m 2004-July-12 Mon = 07/12/2004, monday(07/12/2004, monday) 1\n",
      "\u001b[92m☑\u001b[0m 2002-December-13 Fri = 12/13/2002, friday(12/13/2002, friday) 1\n",
      "\u001b[92m☑\u001b[0m 2005-September-01 Thu = 09/01/2005, thursday(09/01/2005, thursday) 1\n",
      "\u001b[92m☑\u001b[0m 2010-October-20 Wed = 10/20/2010, wednesday(10/20/2010, wednesday) 1\n",
      "\u001b[92m☑\u001b[0m 2008-May-30 Fri = 05/30/2008, friday(05/30/2008, friday) 1\n",
      "Epoch 220. Train Loss: 9.926398e-05, Test Loss : 0.00024112492\n",
      "Epoch 221. Train Loss: 9.5055635e-05, Test Loss : 0.0002402516\n",
      "Epoch 222. Train Loss: 9.236275e-05, Test Loss : 0.00022259413\n",
      "Epoch 223. Train Loss: 9.29511e-05, Test Loss : 0.00021084791\n",
      "Epoch 224. Train Loss: 8.654242e-05, Test Loss : 0.000237893\n",
      "Epoch 225. Train Loss: 8.788396e-05, Test Loss : 0.00022173609\n",
      "Epoch 226. Train Loss: 8.4145424e-05, Test Loss : 0.00017914634\n",
      "Epoch 227. Train Loss: 7.989035e-05, Test Loss : 0.00019690026\n",
      "Epoch 228. Train Loss: 8.63927e-05, Test Loss : 0.00022403765\n",
      "Epoch 229. Train Loss: 7.9848025e-05, Test Loss : 0.0001721427\n",
      "\u001b[92m☑\u001b[0m 2007-February-14 Wed = 02/14/2007, wednesday(02/14/2007, wednesday) 1\n",
      "\u001b[92m☑\u001b[0m 2008-February-09 Sat = 02/09/2008, saturday(02/09/2008, saturday) 1\n",
      "\u001b[92m☑\u001b[0m 2007-January-30 Tue = 01/30/2007, tuesday(01/30/2007, tuesday) 1\n",
      "\u001b[92m☑\u001b[0m 2001-November-06 Tue = 11/06/2001, tuesday(11/06/2001, tuesday) 1\n",
      "\u001b[92m☑\u001b[0m 2005-February-08 Tue = 02/08/2005, tuesday(02/08/2005, tuesday) 1\n",
      "\u001b[92m☑\u001b[0m 2010-May-23 Sun = 05/23/2010, sunday(05/23/2010, sunday) 1\n",
      "\u001b[92m☑\u001b[0m 2009-August-17 Mon = 08/17/2009, monday(08/17/2009, monday) 1\n",
      "\u001b[92m☑\u001b[0m 2009-June-16 Tue = 06/16/2009, tuesday(06/16/2009, tuesday) 1\n",
      "\u001b[92m☑\u001b[0m 2004-September-10 Fri = 09/10/2004, friday(09/10/2004, friday) 1\n",
      "\u001b[92m☑\u001b[0m 2010-April-24 Sat = 04/24/2010, saturday(04/24/2010, saturday) 1\n",
      "Epoch 230. Train Loss: 7.263878e-05, Test Loss : 0.0001605248\n",
      "Epoch 231. Train Loss: 7.702093e-05, Test Loss : 0.00013992841\n",
      "Epoch 232. Train Loss: 7.286336e-05, Test Loss : 0.00019844204\n",
      "Epoch 233. Train Loss: 6.93452e-05, Test Loss : 0.00017185835\n",
      "Epoch 234. Train Loss: 7.110342e-05, Test Loss : 0.00029143947\n",
      "Epoch 235. Train Loss: 6.583115e-05, Test Loss : 0.00015809771\n",
      "Epoch 236. Train Loss: 6.537405e-05, Test Loss : 0.00015096202\n",
      "Epoch 237. Train Loss: 6.510719e-05, Test Loss : 0.00014398553\n",
      "Epoch 238. Train Loss: 6.0906827e-05, Test Loss : 0.00013020383\n",
      "Epoch 239. Train Loss: 6.294295e-05, Test Loss : 0.00012996113\n",
      "\u001b[92m☑\u001b[0m 2011-September-28 Wed = 09/28/2011, wednesday(09/28/2011, wednesday) 1\n",
      "\u001b[92m☑\u001b[0m 2006-May-16 Tue = 05/16/2006, tuesday(05/16/2006, tuesday) 1\n",
      "\u001b[92m☑\u001b[0m 2010-June-07 Mon = 06/07/2010, monday(06/07/2010, monday) 1\n",
      "\u001b[92m☑\u001b[0m 2011-November-25 Fri = 11/25/2011, friday(11/25/2011, friday) 1\n",
      "\u001b[92m☑\u001b[0m 2004-April-19 Mon = 04/19/2004, monday(04/19/2004, monday) 1\n",
      "\u001b[92m☑\u001b[0m 2006-October-24 Tue = 10/24/2006, tuesday(10/24/2006, tuesday) 1\n",
      "\u001b[92m☑\u001b[0m 2006-November-04 Sat = 11/04/2006, saturday(11/04/2006, saturday) 1\n",
      "\u001b[92m☑\u001b[0m 2003-June-13 Fri = 06/13/2003, friday(06/13/2003, friday) 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m☑\u001b[0m 2011-May-21 Sat = 05/21/2011, saturday(05/21/2011, saturday) 1\n",
      "\u001b[92m☑\u001b[0m 2006-May-07 Sun = 05/07/2006, sunday(05/07/2006, sunday) 1\n",
      "Epoch 240. Train Loss: 5.8913847e-05, Test Loss : 0.00015951872\n",
      "Epoch 241. Train Loss: 6.203095e-05, Test Loss : 0.00011133335\n",
      "Epoch 242. Train Loss: 5.709671e-05, Test Loss : 0.000106581116\n",
      "Epoch 243. Train Loss: 5.4627842e-05, Test Loss : 0.000118624244\n",
      "Epoch 244. Train Loss: 5.7310233e-05, Test Loss : 0.000106837906\n",
      "Epoch 245. Train Loss: 5.3130192e-05, Test Loss : 0.000107081345\n",
      "Epoch 246. Train Loss: 5.48358e-05, Test Loss : 0.00010005246\n",
      "Epoch 247. Train Loss: 5.4192227e-05, Test Loss : 0.00015675438\n",
      "Epoch 248. Train Loss: 5.4274627e-05, Test Loss : 0.00010081603\n",
      "Epoch 249. Train Loss: 5.3927113e-05, Test Loss : 0.000104015264\n",
      "\u001b[92m☑\u001b[0m 2002-May-26 Sun = 05/26/2002, sunday(05/26/2002, sunday) 1\n",
      "\u001b[92m☑\u001b[0m 2006-February-27 Mon = 02/27/2006, monday(02/27/2006, monday) 1\n",
      "\u001b[92m☑\u001b[0m 2002-May-23 Thu = 05/23/2002, thursday(05/23/2002, thursday) 1\n",
      "\u001b[92m☑\u001b[0m 2002-October-08 Tue = 10/08/2002, tuesday(10/08/2002, tuesday) 1\n",
      "\u001b[92m☑\u001b[0m 2009-October-13 Tue = 10/13/2009, tuesday(10/13/2009, tuesday) 1\n",
      "\u001b[92m☑\u001b[0m 2011-July-02 Sat = 07/02/2011, saturday(07/02/2011, saturday) 1\n",
      "\u001b[92m☑\u001b[0m 2006-September-14 Thu = 09/14/2006, thursday(09/14/2006, thursday) 1\n",
      "\u001b[92m☑\u001b[0m 2003-June-23 Mon = 06/23/2003, monday(06/23/2003, monday) 1\n",
      "\u001b[92m☑\u001b[0m 2004-October-12 Tue = 10/12/2004, tuesday(10/12/2004, tuesday) 1\n",
      "\u001b[92m☑\u001b[0m 2009-June-06 Sat = 06/06/2009, saturday(06/06/2009, saturday) 1\n",
      "Epoch 250. Train Loss: 5.025404e-05, Test Loss : 9.425778e-05\n",
      "Epoch 251. Train Loss: 4.821232e-05, Test Loss : 0.00011362123\n",
      "Epoch 252. Train Loss: 4.739877e-05, Test Loss : 0.000103423496\n",
      "Epoch 253. Train Loss: 4.6618283e-05, Test Loss : 0.00010059384\n",
      "Epoch 254. Train Loss: 4.7430225e-05, Test Loss : 9.237523e-05\n",
      "Epoch 255. Train Loss: 4.5431963e-05, Test Loss : 9.68779e-05\n",
      "Epoch 256. Train Loss: 4.971201e-05, Test Loss : 0.00010362804\n",
      "Epoch 257. Train Loss: 4.6978224e-05, Test Loss : 8.9430505e-05\n",
      "Epoch 258. Train Loss: 4.5592773e-05, Test Loss : 0.00010548432\n",
      "Epoch 259. Train Loss: 4.3558317e-05, Test Loss : 8.053661e-05\n",
      "\u001b[92m☑\u001b[0m 2006-May-10 Wed = 05/10/2006, wednesday(05/10/2006, wednesday) 1\n",
      "\u001b[92m☑\u001b[0m 2010-July-08 Thu = 07/08/2010, thursday(07/08/2010, thursday) 1\n",
      "\u001b[92m☑\u001b[0m 2008-October-14 Tue = 10/14/2008, tuesday(10/14/2008, tuesday) 1\n",
      "\u001b[92m☑\u001b[0m 2008-November-25 Tue = 11/25/2008, tuesday(11/25/2008, tuesday) 1\n",
      "\u001b[92m☑\u001b[0m 2004-July-16 Fri = 07/16/2004, friday(07/16/2004, friday) 1\n",
      "\u001b[92m☑\u001b[0m 2006-January-18 Wed = 01/18/2006, wednesday(01/18/2006, wednesday) 1\n",
      "\u001b[92m☑\u001b[0m 2011-June-12 Sun = 06/12/2011, sunday(06/12/2011, sunday) 1\n",
      "\u001b[92m☑\u001b[0m 2004-August-28 Sat = 08/28/2004, saturday(08/28/2004, saturday) 1\n",
      "\u001b[92m☑\u001b[0m 2008-January-26 Sat = 01/26/2008, saturday(01/26/2008, saturday) 1\n",
      "\u001b[92m☑\u001b[0m 2010-July-07 Wed = 07/07/2010, wednesday(07/07/2010, wednesday) 1\n",
      "Epoch 260. Train Loss: 4.4693123e-05, Test Loss : 0.00010147349\n",
      "Epoch 261. Train Loss: 4.3197262e-05, Test Loss : 0.00010442627\n",
      "Epoch 262. Train Loss: 4.484316e-05, Test Loss : 8.2450584e-05\n",
      "Epoch 263. Train Loss: 4.421247e-05, Test Loss : 8.518749e-05\n",
      "Epoch 264. Train Loss: 4.1568783e-05, Test Loss : 9.5600626e-05\n",
      "Epoch 265. Train Loss: 4.4377644e-05, Test Loss : 9.600482e-05\n",
      "Epoch 266. Train Loss: 4.326841e-05, Test Loss : 7.508177e-05\n",
      "Epoch 267. Train Loss: 4.222484e-05, Test Loss : 7.597062e-05\n",
      "Epoch 268. Train Loss: 3.924803e-05, Test Loss : 7.8773955e-05\n",
      "Epoch 269. Train Loss: 3.971429e-05, Test Loss : 8.9717534e-05\n",
      "\u001b[92m☑\u001b[0m 2009-August-02 Sun = 08/02/2009, sunday(08/02/2009, sunday) 1\n",
      "\u001b[92m☑\u001b[0m 2002-October-21 Mon = 10/21/2002, monday(10/21/2002, monday) 1\n",
      "\u001b[92m☑\u001b[0m 2003-November-23 Sun = 11/23/2003, sunday(11/23/2003, sunday) 1\n",
      "\u001b[92m☑\u001b[0m 2007-March-13 Tue = 03/13/2007, tuesday(03/13/2007, tuesday) 1\n",
      "\u001b[92m☑\u001b[0m 2004-March-18 Thu = 03/18/2004, thursday(03/18/2004, thursday) 1\n",
      "\u001b[92m☑\u001b[0m 2012-March-21 Wed = 03/21/2012, wednesday(03/21/2012, wednesday) 1\n",
      "\u001b[92m☑\u001b[0m 2004-August-27 Fri = 08/27/2004, friday(08/27/2004, friday) 1\n",
      "\u001b[92m☑\u001b[0m 2003-September-19 Fri = 09/19/2003, friday(09/19/2003, friday) 1\n",
      "\u001b[92m☑\u001b[0m 2006-May-09 Tue = 05/09/2006, tuesday(05/09/2006, tuesday) 1\n",
      "\u001b[92m☑\u001b[0m 2007-November-29 Thu = 11/29/2007, thursday(11/29/2007, thursday) 1\n",
      "Epoch 270. Train Loss: 3.8768576e-05, Test Loss : 8.855803e-05\n",
      "Epoch 271. Train Loss: 3.8372113e-05, Test Loss : 7.5546755e-05\n",
      "Epoch 272. Train Loss: 3.9915565e-05, Test Loss : 8.3306506e-05\n",
      "Epoch 273. Train Loss: 3.9093014e-05, Test Loss : 7.546098e-05\n",
      "Epoch 274. Train Loss: 3.7630445e-05, Test Loss : 7.589088e-05\n",
      "Epoch 275. Train Loss: 3.8819333e-05, Test Loss : 8.22539e-05\n",
      "Epoch 276. Train Loss: 3.7361962e-05, Test Loss : 7.212974e-05\n",
      "Epoch 277. Train Loss: 3.9699484e-05, Test Loss : 8.5046755e-05\n",
      "Epoch 278. Train Loss: 3.733647e-05, Test Loss : 6.91795e-05\n",
      "Epoch 279. Train Loss: 3.5019075e-05, Test Loss : 6.6934736e-05\n",
      "\u001b[92m☑\u001b[0m 2012-June-28 Thu = 06/28/2012, thursday(06/28/2012, thursday) 1\n",
      "\u001b[92m☑\u001b[0m 2011-December-15 Thu = 12/15/2011, thursday(12/15/2011, thursday) 1\n",
      "\u001b[92m☑\u001b[0m 2004-September-22 Wed = 09/22/2004, wednesday(09/22/2004, wednesday) 1\n",
      "\u001b[92m☑\u001b[0m 2004-April-25 Sun = 04/25/2004, sunday(04/25/2004, sunday) 1\n",
      "\u001b[92m☑\u001b[0m 2010-August-21 Sat = 08/21/2010, saturday(08/21/2010, saturday) 1\n",
      "\u001b[92m☑\u001b[0m 2001-November-09 Fri = 11/09/2001, friday(11/09/2001, friday) 1\n",
      "\u001b[92m☑\u001b[0m 2007-February-17 Sat = 02/17/2007, saturday(02/17/2007, saturday) 1\n",
      "\u001b[92m☑\u001b[0m 2012-April-02 Mon = 04/02/2012, monday(04/02/2012, monday) 1\n",
      "\u001b[92m☑\u001b[0m 2012-August-03 Fri = 08/03/2012, friday(08/03/2012, friday) 1\n",
      "\u001b[92m☑\u001b[0m 2004-February-03 Tue = 02/03/2004, tuesday(02/03/2004, tuesday) 1\n",
      "Epoch 280. Train Loss: 3.4658304e-05, Test Loss : 6.8649744e-05\n",
      "Epoch 281. Train Loss: 3.67249e-05, Test Loss : 6.6379114e-05\n",
      "Epoch 282. Train Loss: 3.7828053e-05, Test Loss : 6.377494e-05\n",
      "Epoch 283. Train Loss: 3.489966e-05, Test Loss : 6.838073e-05\n",
      "Epoch 284. Train Loss: 3.4129123e-05, Test Loss : 7.226906e-05\n",
      "Epoch 285. Train Loss: 3.414462e-05, Test Loss : 6.278933e-05\n",
      "Epoch 286. Train Loss: 3.3168362e-05, Test Loss : 6.9666195e-05\n",
      "Epoch 287. Train Loss: 3.2713724e-05, Test Loss : 6.773465e-05\n",
      "Epoch 288. Train Loss: 3.474159e-05, Test Loss : 6.396853e-05\n",
      "Epoch 289. Train Loss: 3.2791024e-05, Test Loss : 7.092156e-05\n",
      "\u001b[92m☑\u001b[0m 2009-June-07 Sun = 06/07/2009, sunday(06/07/2009, sunday) 1\n",
      "\u001b[92m☑\u001b[0m 2012-May-07 Mon = 05/07/2012, monday(05/07/2012, monday) 1\n",
      "\u001b[92m☑\u001b[0m 2007-June-12 Tue = 06/12/2007, tuesday(06/12/2007, tuesday) 1\n",
      "\u001b[92m☑\u001b[0m 2010-October-25 Mon = 10/25/2010, monday(10/25/2010, monday) 1\n",
      "\u001b[92m☑\u001b[0m 2011-September-19 Mon = 09/19/2011, monday(09/19/2011, monday) 1\n",
      "\u001b[92m☑\u001b[0m 2002-August-21 Wed = 08/21/2002, wednesday(08/21/2002, wednesday) 1\n",
      "\u001b[92m☑\u001b[0m 2003-March-18 Tue = 03/18/2003, tuesday(03/18/2003, tuesday) 1\n",
      "\u001b[92m☑\u001b[0m 2003-September-19 Fri = 09/19/2003, friday(09/19/2003, friday) 1\n",
      "\u001b[92m☑\u001b[0m 2010-August-06 Fri = 08/06/2010, friday(08/06/2010, friday) 1\n",
      "\u001b[92m☑\u001b[0m 2006-September-16 Sat = 09/16/2006, saturday(09/16/2006, saturday) 1\n",
      "Epoch 290. Train Loss: 3.1783136e-05, Test Loss : 6.529477e-05\n",
      "Epoch 291. Train Loss: 3.3359654e-05, Test Loss : 6.955177e-05\n",
      "Epoch 292. Train Loss: 3.193807e-05, Test Loss : 6.204903e-05\n",
      "Epoch 293. Train Loss: 3.1921474e-05, Test Loss : 7.1702685e-05\n",
      "Epoch 294. Train Loss: 3.2990956e-05, Test Loss : 6.713207e-05\n",
      "Epoch 295. Train Loss: 3.1432006e-05, Test Loss : 6.1392944e-05\n",
      "Epoch 296. Train Loss: 3.077368e-05, Test Loss : 5.8672013e-05\n",
      "Epoch 297. Train Loss: 3.09704e-05, Test Loss : 5.9927163e-05\n",
      "Epoch 298. Train Loss: 2.9828592e-05, Test Loss : 5.819899e-05\n",
      "Epoch 299. Train Loss: 2.9969675e-05, Test Loss : 5.7721172e-05\n"
     ]
    }
   ],
   "source": [
    "res = train(model, tr_data_iterator, te_data_iterator \\\n",
    "          , trainer, loss, char_indices, indices_char\n",
    "          , epochs= 300, ctx = ctx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input: 2004-April-24 Sat, length: 17\n",
      "prediction: 04/24/2004, saturday, length:20\n",
      "attention shape= (20, 32)\n",
      "check attn = [1.         1.         0.99999994 1.         0.99999994 0.99999994\n",
      " 1.         1.         0.99999994 0.99999994 1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.        ]\n",
      "val shape= (20, 17)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "example = [gen_date() for _ in range(1)]\n",
    "plot_attention(model, example, char_indices, indices_char, in_seq_len)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
