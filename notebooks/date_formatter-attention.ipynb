{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import numpy as np\n",
    "import mxnet as mx\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from datetime import datetime\n",
    "\n",
    "sys.path.append(\"../python/\")\n",
    "from date_format_translator_attention import *\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 1000\n",
    "N_train = int(N * .9)\n",
    "N_validation = N - N_train\n",
    "\n",
    "in_seq_len = 32\n",
    "out_seq_len = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X, Y, Z, chars, char_indices, indices_char = generate_date_data(N)\n",
    "\n",
    "# Split data\n",
    "X_train, X_validation, Y_train, Y_validation, Z_train, Z_validation = \\\n",
    "    train_test_split(X, Y, Z, train_size = N_train)\n",
    "\n",
    "# Create dataloader\n",
    "tr_set = gluon.data.ArrayDataset(X_train, Y_train, Z_train)\n",
    "tr_data_iterator = gluon.data.DataLoader(tr_set, batch_size=256, shuffle=True)\n",
    "\n",
    "te_set =gluon.data.ArrayDataset(X_validation, Y_validation, Z_validation)\n",
    "te_data_iterator = gluon.data.DataLoader(te_set, batch_size=256, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define model, trainer, and loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctx = mx.gpu()\n",
    "model = format_translator(300, in_seq_len, out_seq_len, len(chars), ctx)\n",
    "model.collect_params().initialize(mx.init.Xavier(), ctx = ctx)\n",
    "\n",
    "trainer = gluon.Trainer(model.collect_params(), 'rmsprop')\n",
    "loss = gluon.loss.SoftmaxCrossEntropyLoss(axis = 2, sparse_label = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[91m☒\u001b[0m 2003-December-28 Sun = 23/28/2003, sunday(12/28/2003, sunday) 0\n",
      "\u001b[92m☑\u001b[0m 2003-July-22 Tue = 07/22/2003, tuesday(07/22/2003, tuesday) 1\n",
      "\u001b[91m☒\u001b[0m 2008-October-13 Mon = 03/18/2003, monday(10/13/2008, monday) 0\n",
      "\u001b[91m☒\u001b[0m 2011-January-10 Mon = 01/11/2000, monday(01/10/2011, monday) 0\n",
      "\u001b[91m☒\u001b[0m 2012-July-16 Mon = 06/27/2006, monday(07/16/2012, monday) 0\n",
      "\u001b[91m☒\u001b[0m 2012-September-30 Sun = 09/23/2009, sunday(09/30/2012, sunday) 0\n",
      "\u001b[91m☒\u001b[0m 2011-August-29 Mon = 08/29/2008, monday(08/29/2011, monday) 0\n",
      "\u001b[91m☒\u001b[0m 2009-February-09 Mon = 09/20/209, monday(02/09/2009, monday) 0\n",
      "\u001b[91m☒\u001b[0m 2012-April-06 Fri = 04/26/2004, friday(04/06/2012, friday) 0\n",
      "\u001b[91m☒\u001b[0m 2005-July-08 Fri = 05/08/2008, friday(07/08/2005, friday) 0\n",
      "Epoch 0. Train Loss: 0.119648464, Test Loss : 0.1484165\n",
      "Epoch 1. Train Loss: 0.115584336, Test Loss : 0.17849718\n",
      "Epoch 2. Train Loss: 0.1356239, Test Loss : 0.41998872\n",
      "Epoch 3. Train Loss: 0.14000238, Test Loss : 0.11697188\n",
      "Epoch 4. Train Loss: 0.09727065, Test Loss : 0.115161344\n",
      "Epoch 5. Train Loss: 0.12412268, Test Loss : 0.15998113\n",
      "Epoch 6. Train Loss: 0.09830745, Test Loss : 0.11600861\n",
      "Epoch 7. Train Loss: 0.105251566, Test Loss : 0.13982669\n",
      "Epoch 8. Train Loss: 0.10112761, Test Loss : 0.111984015\n",
      "Epoch 9. Train Loss: 0.09310675, Test Loss : 0.12010611\n",
      "\u001b[92m☑\u001b[0m 2004-February-06 Fri = 02/06/2004, friday(02/06/2004, friday) 1\n",
      "\u001b[91m☒\u001b[0m 2010-March-27 Sat = 03/27/2003, saturday(03/27/2010, saturday) 0\n",
      "\u001b[92m☑\u001b[0m 2011-January-16 Sun = 01/16/2011, sunday(01/16/2011, sunday) 1\n",
      "\u001b[92m☑\u001b[0m 2006-December-15 Fri = 12/15/2006, friday(12/15/2006, friday) 1\n",
      "\u001b[92m☑\u001b[0m 2008-November-28 Fri = 11/28/2008, friday(11/28/2008, friday) 1\n",
      "\u001b[92m☑\u001b[0m 2007-August-05 Sun = 08/05/2007, sunday(08/05/2007, sunday) 1\n",
      "\u001b[91m☒\u001b[0m 2001-September-14 Fri = 04/11/2007, friday(09/14/2001, friday) 0\n",
      "\u001b[91m☒\u001b[0m 2011-February-23 Wed = 02/12/2003, wednesday(02/23/2011, wednesday) 0\n",
      "\u001b[91m☒\u001b[0m 2009-July-21 Tue = 07/29/2001, tuesday(07/21/2009, tuesday) 0\n",
      "\u001b[91m☒\u001b[0m 2005-May-20 Fri = 05/05/2002, friday(05/20/2005, friday) 0\n",
      "Epoch 10. Train Loss: 0.09270773, Test Loss : 0.09109949\n",
      "Epoch 11. Train Loss: 0.076854944, Test Loss : 0.11598147\n",
      "Epoch 12. Train Loss: 0.10558773, Test Loss : 0.08863269\n",
      "Epoch 13. Train Loss: 0.07828155, Test Loss : 0.09532948\n",
      "Epoch 14. Train Loss: 0.07988824, Test Loss : 0.08466359\n",
      "Epoch 15. Train Loss: 0.076924086, Test Loss : 0.112970114\n",
      "Epoch 16. Train Loss: 0.077002645, Test Loss : 0.0654903\n",
      "Epoch 17. Train Loss: 0.056134567, Test Loss : 0.09049552\n",
      "Epoch 18. Train Loss: 0.07871666, Test Loss : 0.09606333\n",
      "Epoch 19. Train Loss: 0.06820181, Test Loss : 0.08264741\n",
      "\u001b[92m☑\u001b[0m 2007-March-16 Fri = 03/16/2007, friday(03/16/2007, friday) 1\n",
      "\u001b[91m☒\u001b[0m 2010-May-25 Tue = 05/25/2002, tuesday(05/25/2010, tuesday) 0\n",
      "\u001b[92m☑\u001b[0m 2009-May-14 Thu = 05/14/2009, thursday(05/14/2009, thursday) 1\n",
      "\u001b[92m☑\u001b[0m 2005-March-14 Mon = 03/14/2005, monday(03/14/2005, monday) 1\n",
      "\u001b[91m☒\u001b[0m 2010-August-29 Sun = 08/29/2002, sunday(08/29/2010, sunday) 0\n",
      "\u001b[91m☒\u001b[0m 2010-February-08 Mon = 02/08/2002, monday(02/08/2010, monday) 0\n",
      "\u001b[91m☒\u001b[0m 2010-November-13 Sat = 11/31/2001, saturday(11/13/2010, saturday) 0\n",
      "\u001b[91m☒\u001b[0m 2006-March-02 Thu = 03/20/2006, thursday(03/02/2006, thursday) 0\n",
      "\u001b[91m☒\u001b[0m 2007-April-13 Fri = 04/31/2007, friday(04/13/2007, friday) 0\n",
      "\u001b[92m☑\u001b[0m 2004-July-28 Wed = 07/28/2004, wednesday(07/28/2004, wednesday) 1\n",
      "Epoch 20. Train Loss: 0.060368817, Test Loss : 0.07727298\n",
      "Epoch 21. Train Loss: 0.060231663, Test Loss : 0.07480781\n",
      "Epoch 22. Train Loss: 0.05240999, Test Loss : 0.09795772\n",
      "Epoch 23. Train Loss: 0.07419846, Test Loss : 0.11342747\n",
      "Epoch 24. Train Loss: 0.0692589, Test Loss : 0.06236218\n",
      "Epoch 25. Train Loss: 0.039176993, Test Loss : 0.05354549\n",
      "Epoch 26. Train Loss: 0.058572665, Test Loss : 0.07996459\n",
      "Epoch 27. Train Loss: 0.04776971, Test Loss : 0.059057284\n",
      "Epoch 28. Train Loss: 0.054035675, Test Loss : 0.060405098\n",
      "Epoch 29. Train Loss: 0.038160726, Test Loss : 0.04846685\n",
      "\u001b[91m☒\u001b[0m 2009-November-22 Sun = 12/12/2009, sunday(11/22/2009, sunday) 0\n",
      "\u001b[91m☒\u001b[0m 2007-April-10 Tue = 04/07/010, tuesday(04/10/2007, tuesday) 0\n",
      "\u001b[91m☒\u001b[0m 2009-March-29 Sun = 03/99/2015, sunday(03/29/2009, sunday) 0\n",
      "\u001b[91m☒\u001b[0m 2007-December-15 Sat = 12/17/2010, saturday(12/15/2007, saturday) 0\n",
      "\u001b[91m☒\u001b[0m 2009-January-12 Mon = 01/19/2001, monday(01/12/2009, monday) 0\n",
      "\u001b[91m☒\u001b[0m 2012-January-14 Sat = 01/14/2011, saturday(01/14/2012, saturday) 0\n",
      "\u001b[91m☒\u001b[0m 2006-April-20 Thu = 04/06/2004, thursday(04/20/2006, thursday) 0\n",
      "\u001b[91m☒\u001b[0m 2011-November-21 Mon = 11/11/2012, monday(11/21/2011, monday) 0\n",
      "\u001b[92m☑\u001b[0m 2009-August-17 Mon = 08/17/2009, monday(08/17/2009, monday) 1\n",
      "\u001b[91m☒\u001b[0m 2009-November-24 Tue = 12/14/2009, tuesday(11/24/2009, tuesday) 0\n",
      "Epoch 30. Train Loss: 0.06283942, Test Loss : 0.12561373\n",
      "Epoch 31. Train Loss: 0.053893995, Test Loss : 0.04257263\n",
      "Epoch 32. Train Loss: 0.03814779, Test Loss : 0.07486121\n",
      "Epoch 33. Train Loss: 0.044462558, Test Loss : 0.04359618\n",
      "Epoch 34. Train Loss: 0.036043566, Test Loss : 0.05704643\n",
      "Epoch 35. Train Loss: 0.041171253, Test Loss : 0.16000067\n",
      "Epoch 36. Train Loss: 0.06776516, Test Loss : 0.039602824\n",
      "Epoch 37. Train Loss: 0.026924035, Test Loss : 0.032577835\n",
      "Epoch 38. Train Loss: 0.043443106, Test Loss : 0.09548854\n",
      "Epoch 39. Train Loss: 0.049860664, Test Loss : 0.045734134\n",
      "\u001b[92m☑\u001b[0m 2004-August-26 Thu = 08/26/2004, thursday(08/26/2004, thursday) 1\n",
      "\u001b[92m☑\u001b[0m 2009-October-14 Wed = 10/14/2009, wednesday(10/14/2009, wednesday) 1\n",
      "\u001b[91m☒\u001b[0m 2005-November-14 Mon = 11/14/2001, monday(11/14/2005, monday) 0\n",
      "\u001b[91m☒\u001b[0m 2002-March-20 Wed = 03/20/2012, wednesday(03/20/2002, wednesday) 0\n",
      "\u001b[91m☒\u001b[0m 2001-November-29 Thu = 11/29/2011, thursday(11/29/2001, thursday) 0\n",
      "\u001b[91m☒\u001b[0m 2006-March-28 Tue = 03/28/2016, tuesday(03/28/2006, tuesday) 0\n",
      "\u001b[91m☒\u001b[0m 2011-January-08 Sat = 01/18/2010, saturday(01/08/2011, saturday) 0\n",
      "\u001b[92m☑\u001b[0m 2004-August-26 Thu = 08/26/2004, thursday(08/26/2004, thursday) 1\n",
      "\u001b[91m☒\u001b[0m 2009-March-02 Mon = 03/20/2009, monday(03/02/2009, monday) 0\n",
      "\u001b[92m☑\u001b[0m 2010-August-24 Tue = 08/24/2010, tuesday(08/24/2010, tuesday) 1\n",
      "Epoch 40. Train Loss: 0.03602975, Test Loss : 0.068765886\n",
      "Epoch 41. Train Loss: 0.039641418, Test Loss : 0.038602218\n",
      "Epoch 42. Train Loss: 0.028974116, Test Loss : 0.03921397\n",
      "Epoch 43. Train Loss: 0.03912098, Test Loss : 0.061946284\n",
      "Epoch 44. Train Loss: 0.04423188, Test Loss : 0.06217047\n",
      "Epoch 45. Train Loss: 0.03850742, Test Loss : 0.04289505\n",
      "Epoch 46. Train Loss: 0.027643463, Test Loss : 0.04137923\n",
      "Epoch 47. Train Loss: 0.05405932, Test Loss : 0.19912046\n",
      "Epoch 48. Train Loss: 0.0408046, Test Loss : 0.026345838\n",
      "Epoch 49. Train Loss: 0.02125993, Test Loss : 0.024475243\n",
      "\u001b[92m☑\u001b[0m 2003-September-16 Tue = 09/16/2003, tuesday(09/16/2003, tuesday) 1\n",
      "\u001b[92m☑\u001b[0m 2007-May-01 Tue = 05/01/2007, tuesday(05/01/2007, tuesday) 1\n",
      "\u001b[92m☑\u001b[0m 2003-August-15 Fri = 08/15/2003, friday(08/15/2003, friday) 1\n",
      "\u001b[92m☑\u001b[0m 2009-November-21 Sat = 11/21/2009, saturday(11/21/2009, saturday) 1\n",
      "\u001b[92m☑\u001b[0m 2012-October-07 Sun = 10/07/2012, sunday(10/07/2012, sunday) 1\n",
      "\u001b[92m☑\u001b[0m 2006-April-21 Fri = 04/21/2006, friday(04/21/2006, friday) 1\n",
      "\u001b[91m☒\u001b[0m 2012-May-12 Sat = 05/21/2012, saturday(05/12/2012, saturday) 0\n",
      "\u001b[92m☑\u001b[0m 2009-November-27 Fri = 11/27/2009, friday(11/27/2009, friday) 1\n",
      "\u001b[92m☑\u001b[0m 2007-April-29 Sun = 04/29/2007, sunday(04/29/2007, sunday) 1\n",
      "\u001b[92m☑\u001b[0m 2010-June-30 Wed = 06/30/2010, wednesday(06/30/2010, wednesday) 1\n",
      "Epoch 50. Train Loss: 0.018602349, Test Loss : 0.0314346\n",
      "Epoch 51. Train Loss: 0.055846743, Test Loss : 0.06731361\n",
      "Epoch 52. Train Loss: 0.033197418, Test Loss : 0.044370223\n",
      "Epoch 53. Train Loss: 0.032405887, Test Loss : 0.06773697\n",
      "Epoch 54. Train Loss: 0.027670965, Test Loss : 0.02166249\n",
      "Epoch 55. Train Loss: 0.017298842, Test Loss : 0.037569568\n",
      "Epoch 56. Train Loss: 0.03721518, Test Loss : 0.07890921\n",
      "Epoch 57. Train Loss: 0.029110335, Test Loss : 0.05131259\n",
      "Epoch 58. Train Loss: 0.042436846, Test Loss : 0.12434027\n",
      "Epoch 59. Train Loss: 0.03415488, Test Loss : 0.029019153\n",
      "\u001b[91m☒\u001b[0m 2001-December-04 Tue = 12/04/2010, tuesday(12/04/2001, tuesday) 0\n",
      "\u001b[92m☑\u001b[0m 2006-November-10 Fri = 11/10/2006, friday(11/10/2006, friday) 1\n",
      "\u001b[92m☑\u001b[0m 2003-November-21 Fri = 11/21/2003, friday(11/21/2003, friday) 1\n",
      "\u001b[92m☑\u001b[0m 2008-March-21 Fri = 03/21/2008, friday(03/21/2008, friday) 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m☑\u001b[0m 2011-February-08 Tue = 02/08/2011, tuesday(02/08/2011, tuesday) 1\n",
      "\u001b[92m☑\u001b[0m 2011-October-30 Sun = 10/30/2011, sunday(10/30/2011, sunday) 1\n",
      "\u001b[92m☑\u001b[0m 2002-October-17 Thu = 10/17/2002, thursday(10/17/2002, thursday) 1\n",
      "\u001b[92m☑\u001b[0m 2006-August-26 Sat = 08/26/2006, saturday(08/26/2006, saturday) 1\n",
      "\u001b[92m☑\u001b[0m 2003-November-04 Tue = 11/04/2003, tuesday(11/04/2003, tuesday) 1\n",
      "\u001b[92m☑\u001b[0m 2007-March-05 Mon = 03/05/2007, monday(03/05/2007, monday) 1\n",
      "Epoch 60. Train Loss: 0.018212743, Test Loss : 0.019315822\n",
      "Epoch 61. Train Loss: 0.022739619, Test Loss : 0.0684603\n",
      "Epoch 62. Train Loss: 0.04788778, Test Loss : 0.04943214\n",
      "Epoch 63. Train Loss: 0.027661555, Test Loss : 0.036147214\n",
      "Epoch 64. Train Loss: 0.029294027, Test Loss : 0.023333637\n",
      "Epoch 65. Train Loss: 0.01952156, Test Loss : 0.048837826\n",
      "Epoch 66. Train Loss: 0.023431282, Test Loss : 0.026181076\n",
      "Epoch 67. Train Loss: 0.020859184, Test Loss : 0.039445583\n",
      "Epoch 68. Train Loss: 0.028144475, Test Loss : 0.03409827\n",
      "Epoch 69. Train Loss: 0.027000034, Test Loss : 0.03928253\n",
      "\u001b[91m☒\u001b[0m 2008-November-21 Fri = 11/21/2005, monday(11/21/2008, friday) 0\n",
      "\u001b[91m☒\u001b[0m 2010-July-10 Sat = 07/01/2010, saturday(07/10/2010, saturday) 0\n",
      "\u001b[92m☑\u001b[0m 2005-January-22 Sat = 01/22/2005, saturday(01/22/2005, saturday) 1\n",
      "\u001b[91m☒\u001b[0m 2005-May-05 Thu = 05/05/20550, thurs5day(05/05/2005, thursday) 0\n",
      "\u001b[92m☑\u001b[0m 2004-May-23 Sun = 05/23/2004, sunday(05/23/2004, sunday) 1\n",
      "\u001b[92m☑\u001b[0m 2002-July-20 Sat = 07/20/2002, saturday(07/20/2002, saturday) 1\n",
      "\u001b[91m☒\u001b[0m 2007-June-25 Mon = 05/27/2005, monday(06/25/2007, monday) 0\n",
      "\u001b[91m☒\u001b[0m 2005-June-23 Thu = 06/23/20505, thursday(06/23/2005, thursday) 0\n",
      "\u001b[92m☑\u001b[0m 2007-January-01 Mon = 01/01/2007, monday(01/01/2007, monday) 1\n",
      "\u001b[92m☑\u001b[0m 2004-April-07 Wed = 04/07/2004, wednesday(04/07/2004, wednesday) 1\n",
      "Epoch 70. Train Loss: 0.029802985, Test Loss : 0.12881519\n",
      "Epoch 71. Train Loss: 0.038725045, Test Loss : 0.08193299\n",
      "Epoch 72. Train Loss: 0.02492033, Test Loss : 0.02219506\n",
      "Epoch 73. Train Loss: 0.014783617, Test Loss : 0.026911449\n",
      "Epoch 74. Train Loss: 0.018362856, Test Loss : 0.050070852\n",
      "Epoch 75. Train Loss: 0.040356997, Test Loss : 0.09025561\n",
      "Epoch 76. Train Loss: 0.02109486, Test Loss : 0.03878166\n",
      "Epoch 77. Train Loss: 0.03441225, Test Loss : 0.0748028\n",
      "Epoch 78. Train Loss: 0.021236435, Test Loss : 0.0193335\n",
      "Epoch 79. Train Loss: 0.0133410795, Test Loss : 0.01900234\n",
      "\u001b[92m☑\u001b[0m 2008-June-06 Fri = 06/06/2008, friday(06/06/2008, friday) 1\n",
      "\u001b[91m☒\u001b[0m 2011-April-10 Sun = 04/01/2011, sunday(04/10/2011, sunday) 0\n",
      "\u001b[92m☑\u001b[0m 2012-July-23 Mon = 07/23/2012, monday(07/23/2012, monday) 1\n",
      "\u001b[92m☑\u001b[0m 2009-July-08 Wed = 07/08/2009, wednesday(07/08/2009, wednesday) 1\n",
      "\u001b[92m☑\u001b[0m 2006-August-19 Sat = 08/19/2006, saturday(08/19/2006, saturday) 1\n",
      "\u001b[92m☑\u001b[0m 2008-March-27 Thu = 03/27/2008, thursday(03/27/2008, thursday) 1\n",
      "\u001b[92m☑\u001b[0m 2005-November-09 Wed = 11/09/2005, wednesday(11/09/2005, wednesday) 1\n",
      "\u001b[92m☑\u001b[0m 2007-September-15 Sat = 09/15/2007, saturday(09/15/2007, saturday) 1\n",
      "\u001b[92m☑\u001b[0m 2010-July-17 Sat = 07/17/2010, saturday(07/17/2010, saturday) 1\n",
      "\u001b[92m☑\u001b[0m 2006-December-18 Mon = 12/18/2006, monday(12/18/2006, monday) 1\n",
      "Epoch 80. Train Loss: 0.014198731, Test Loss : 0.027802603\n",
      "Epoch 81. Train Loss: 0.017503407, Test Loss : 0.031320453\n",
      "Epoch 82. Train Loss: 0.02112468, Test Loss : 0.07104401\n",
      "Epoch 83. Train Loss: 0.032159626, Test Loss : 0.040330194\n",
      "Epoch 84. Train Loss: 0.02906104, Test Loss : 0.03525417\n",
      "Epoch 85. Train Loss: 0.023023017, Test Loss : 0.02134469\n",
      "Epoch 86. Train Loss: 0.015796397, Test Loss : 0.020596238\n",
      "Epoch 87. Train Loss: 0.019764662, Test Loss : 0.14130172\n",
      "Epoch 88. Train Loss: 0.03706961, Test Loss : 0.023521988\n",
      "Epoch 89. Train Loss: 0.01509066, Test Loss : 0.02822985\n",
      "\u001b[92m☑\u001b[0m 2009-July-30 Thu = 07/30/2009, thursday(07/30/2009, thursday) 1\n",
      "\u001b[92m☑\u001b[0m 2003-April-30 Wed = 04/30/2003, wednesday(04/30/2003, wednesday) 1\n",
      "\u001b[92m☑\u001b[0m 2007-December-17 Mon = 12/17/2007, monday(12/17/2007, monday) 1\n",
      "\u001b[91m☒\u001b[0m 2001-September-16 Sun = 09/16/2010, sunday(09/16/2001, sunday) 0\n",
      "\u001b[92m☑\u001b[0m 2002-October-18 Fri = 10/18/2002, friday(10/18/2002, friday) 1\n",
      "\u001b[92m☑\u001b[0m 2004-May-22 Sat = 05/22/2004, saturday(05/22/2004, saturday) 1\n",
      "\u001b[92m☑\u001b[0m 2010-December-29 Wed = 12/29/2010, wednesday(12/29/2010, wednesday) 1\n",
      "\u001b[92m☑\u001b[0m 2009-October-23 Fri = 10/23/2009, friday(10/23/2009, friday) 1\n",
      "\u001b[92m☑\u001b[0m 2004-December-22 Wed = 12/22/2004, wednesday(12/22/2004, wednesday) 1\n",
      "\u001b[92m☑\u001b[0m 2011-May-09 Mon = 05/09/2011, monday(05/09/2011, monday) 1\n",
      "Epoch 90. Train Loss: 0.014130561, Test Loss : 0.020840557\n",
      "Epoch 91. Train Loss: 0.014318236, Test Loss : 0.021430163\n",
      "Epoch 92. Train Loss: 0.025070678, Test Loss : 0.105047874\n",
      "Epoch 93. Train Loss: 0.04399716, Test Loss : 0.027434\n",
      "Epoch 94. Train Loss: 0.017893368, Test Loss : 0.05835152\n",
      "Epoch 95. Train Loss: 0.024628215, Test Loss : 0.016142758\n",
      "Epoch 96. Train Loss: 0.014761409, Test Loss : 0.023728304\n",
      "Epoch 97. Train Loss: 0.012516199, Test Loss : 0.016929545\n",
      "Epoch 98. Train Loss: 0.016651325, Test Loss : 0.023482688\n",
      "Epoch 99. Train Loss: 0.013805654, Test Loss : 0.02266202\n",
      "\u001b[91m☒\u001b[0m 2003-February-15 Sat = 01/25/2003, saturday(02/15/2003, saturday) 0\n",
      "\u001b[91m☒\u001b[0m 2004-October-02 Sat = 01/05/2002, saturday(10/02/2004, saturday) 0\n",
      "\u001b[91m☒\u001b[0m 2006-July-03 Mon = 07/30/2006, monday(07/03/2006, monday) 0\n",
      "\u001b[91m☒\u001b[0m 2012-August-01 Wed = 08/10/20/2015, wednesday(08/01/2012, wednesday) 0\n",
      "\u001b[91m☒\u001b[0m 2007-May-27 Sun = 05/27/207/25/207sunday(05/27/2007, sunday) 0\n",
      "\u001b[91m☒\u001b[0m 2003-June-20 Fri = 06/02/2005, friday(06/20/2003, friday) 0\n",
      "\u001b[92m☑\u001b[0m 2004-March-30 Tue = 03/30/2004, tuesday(03/30/2004, tuesday) 1\n",
      "\u001b[91m☒\u001b[0m 2011-April-06 Wed = 04/16/2005, wednesday(04/06/2011, wednesday) 0\n",
      "\u001b[91m☒\u001b[0m 2010-September-30 Thu = 09/03/20/05/2013, thursday(09/30/2010, thursday) 0\n",
      "\u001b[92m☑\u001b[0m 2009-October-30 Fri = 10/30/2009, friday(10/30/2009, friday) 1\n",
      "Epoch 100. Train Loss: 0.02695816, Test Loss : 0.100474566\n",
      "Epoch 101. Train Loss: 0.047860555, Test Loss : 0.045259964\n",
      "Epoch 102. Train Loss: 0.017439503, Test Loss : 0.0258435\n",
      "Epoch 103. Train Loss: 0.011274819, Test Loss : 0.020751173\n",
      "Epoch 104. Train Loss: 0.0109842615, Test Loss : 0.017151639\n",
      "Epoch 105. Train Loss: 0.013472615, Test Loss : 0.014560702\n",
      "Epoch 106. Train Loss: 0.011896763, Test Loss : 0.032549426\n",
      "Epoch 107. Train Loss: 0.02570738, Test Loss : 0.06641745\n",
      "Epoch 108. Train Loss: 0.022975817, Test Loss : 0.016011544\n",
      "Epoch 109. Train Loss: 0.010814402, Test Loss : 0.017421404\n",
      "\u001b[92m☑\u001b[0m 2004-February-19 Thu = 02/19/2004, thursday(02/19/2004, thursday) 1\n",
      "\u001b[92m☑\u001b[0m 2011-May-14 Sat = 05/14/2011, saturday(05/14/2011, saturday) 1\n",
      "\u001b[92m☑\u001b[0m 2006-April-21 Fri = 04/21/2006, friday(04/21/2006, friday) 1\n",
      "\u001b[91m☒\u001b[0m 2010-August-31 Tue = 08/13/2010, tuesday(08/31/2010, tuesday) 0\n",
      "\u001b[92m☑\u001b[0m 2006-May-11 Thu = 05/11/2006, thursday(05/11/2006, thursday) 1\n",
      "\u001b[92m☑\u001b[0m 2006-October-27 Fri = 10/27/2006, friday(10/27/2006, friday) 1\n",
      "\u001b[91m☒\u001b[0m 2010-November-25 Thu = 11/25/2001, thursday(11/25/2010, thursday) 0\n",
      "\u001b[92m☑\u001b[0m 2002-December-06 Fri = 12/06/2002, friday(12/06/2002, friday) 1\n",
      "\u001b[92m☑\u001b[0m 2007-May-24 Thu = 05/24/2007, thursday(05/24/2007, thursday) 1\n",
      "\u001b[92m☑\u001b[0m 2009-December-19 Sat = 12/19/2009, saturday(12/19/2009, saturday) 1\n",
      "Epoch 110. Train Loss: 0.014014893, Test Loss : 0.012790687\n",
      "Epoch 111. Train Loss: 0.01361101, Test Loss : 0.044400703\n",
      "Epoch 112. Train Loss: 0.032512557, Test Loss : 0.06560309\n",
      "Epoch 113. Train Loss: 0.02348964, Test Loss : 0.04588773\n",
      "Epoch 114. Train Loss: 0.015418407, Test Loss : 0.04055232\n",
      "Epoch 115. Train Loss: 0.015033529, Test Loss : 0.017054627\n",
      "Epoch 116. Train Loss: 0.01503811, Test Loss : 0.014769929\n",
      "Epoch 117. Train Loss: 0.008866222, Test Loss : 0.018298514\n",
      "Epoch 118. Train Loss: 0.0137279555, Test Loss : 0.02315851\n",
      "Epoch 119. Train Loss: 0.013307634, Test Loss : 0.038421847\n",
      "\u001b[92m☑\u001b[0m 2011-March-04 Fri = 03/04/2011, friday(03/04/2011, friday) 1\n",
      "\u001b[91m☒\u001b[0m 2012-July-09 Mon = 07/09/2010, monday(07/09/2012, monday) 0\n",
      "\u001b[92m☑\u001b[0m 2005-February-20 Sun = 02/20/2005, sunday(02/20/2005, sunday) 1\n",
      "\u001b[92m☑\u001b[0m 2001-October-01 Mon = 10/01/2001, monday(10/01/2001, monday) 1\n",
      "\u001b[91m☒\u001b[0m 2011-August-02 Tue = 08/20/2011, tuesday(08/02/2011, tuesday) 0\n",
      "\u001b[92m☑\u001b[0m 2003-August-18 Mon = 08/18/2003, monday(08/18/2003, monday) 1\n",
      "\u001b[91m☒\u001b[0m 2010-October-08 Fri = 10/08/2001, friday(10/08/2010, friday) 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m☑\u001b[0m 2005-December-28 Wed = 12/28/2005, wednesday(12/28/2005, wednesday) 1\n",
      "\u001b[92m☑\u001b[0m 2009-March-23 Mon = 03/23/2009, monday(03/23/2009, monday) 1\n",
      "\u001b[92m☑\u001b[0m 2004-February-22 Sun = 02/22/2004, sunday(02/22/2004, sunday) 1\n",
      "Epoch 120. Train Loss: 0.0129570495, Test Loss : 0.02477821\n",
      "Epoch 121. Train Loss: 0.02340966, Test Loss : 0.05256362\n",
      "Epoch 122. Train Loss: 0.02686026, Test Loss : 0.10306763\n",
      "Epoch 123. Train Loss: 0.034034118, Test Loss : 0.02111026\n",
      "Epoch 124. Train Loss: 0.008544492, Test Loss : 0.012675341\n",
      "Epoch 125. Train Loss: 0.008089196, Test Loss : 0.02063042\n",
      "Epoch 126. Train Loss: 0.012775487, Test Loss : 0.025152724\n",
      "Epoch 127. Train Loss: 0.018135503, Test Loss : 0.016991049\n",
      "Epoch 128. Train Loss: 0.006808158, Test Loss : 0.012384661\n",
      "Epoch 129. Train Loss: 0.0096997, Test Loss : 0.020718182\n",
      "\u001b[92m☑\u001b[0m 2004-July-18 Sun = 07/18/2004, sunday(07/18/2004, sunday) 1\n",
      "\u001b[91m☒\u001b[0m 2006-March-30 Thu = 03/03/2006, thursday(03/30/2006, thursday) 0\n",
      "\u001b[92m☑\u001b[0m 2008-March-04 Tue = 03/04/2008, tuesday(03/04/2008, tuesday) 1\n",
      "\u001b[92m☑\u001b[0m 2007-November-24 Sat = 11/24/2007, saturday(11/24/2007, saturday) 1\n",
      "\u001b[92m☑\u001b[0m 2009-August-24 Mon = 08/24/2009, monday(08/24/2009, monday) 1\n",
      "\u001b[92m☑\u001b[0m 2006-February-22 Wed = 02/22/2006, wednesday(02/22/2006, wednesday) 1\n",
      "\u001b[92m☑\u001b[0m 2009-December-22 Tue = 12/22/2009, tuesday(12/22/2009, tuesday) 1\n",
      "\u001b[92m☑\u001b[0m 2011-March-26 Sat = 03/26/2011, saturday(03/26/2011, saturday) 1\n",
      "\u001b[92m☑\u001b[0m 2006-March-14 Tue = 03/14/2006, tuesday(03/14/2006, tuesday) 1\n",
      "\u001b[92m☑\u001b[0m 2004-November-21 Sun = 11/21/2004, sunday(11/21/2004, sunday) 1\n",
      "Epoch 130. Train Loss: 0.018492807, Test Loss : 0.049360685\n",
      "Epoch 131. Train Loss: 0.027326185, Test Loss : 0.04033721\n",
      "Epoch 132. Train Loss: 0.010896027, Test Loss : 0.014476491\n",
      "Epoch 133. Train Loss: 0.008260887, Test Loss : 0.020131733\n",
      "Epoch 134. Train Loss: 0.015264116, Test Loss : 0.011807894\n",
      "Epoch 135. Train Loss: 0.008201782, Test Loss : 0.037678543\n",
      "Epoch 136. Train Loss: 0.017110271, Test Loss : 0.040071994\n",
      "Epoch 137. Train Loss: 0.012136829, Test Loss : 0.027602598\n",
      "Epoch 138. Train Loss: 0.021408305, Test Loss : 0.05059625\n",
      "Epoch 139. Train Loss: 0.035550255, Test Loss : 0.1244979\n",
      "\u001b[92m☑\u001b[0m 2011-June-10 Fri = 06/10/2011, friday(06/10/2011, friday) 1\n",
      "\u001b[92m☑\u001b[0m 2005-April-11 Mon = 04/11/2005, monday(04/11/2005, monday) 1\n",
      "\u001b[92m☑\u001b[0m 2010-March-14 Sun = 03/14/2010, sunday(03/14/2010, sunday) 1\n",
      "\u001b[92m☑\u001b[0m 2011-April-29 Fri = 04/29/2011, friday(04/29/2011, friday) 1\n",
      "\u001b[92m☑\u001b[0m 2007-February-20 Tue = 02/20/2007, tuesday(02/20/2007, tuesday) 1\n",
      "\u001b[91m☒\u001b[0m 2007-August-30 Thu = 08/03/2007, thursday(08/30/2007, thursday) 0\n",
      "\u001b[92m☑\u001b[0m 2011-February-05 Sat = 02/05/2011, saturday(02/05/2011, saturday) 1\n",
      "\u001b[92m☑\u001b[0m 2007-January-23 Tue = 01/23/2007, tuesday(01/23/2007, tuesday) 1\n",
      "\u001b[91m☒\u001b[0m 2001-September-09 Sun = 09/09/2010, sunday(09/09/2001, sunday) 0\n",
      "\u001b[92m☑\u001b[0m 2002-October-29 Tue = 10/29/2002, tuesday(10/29/2002, tuesday) 1\n",
      "Epoch 140. Train Loss: 0.017121626, Test Loss : 0.0155169275\n",
      "Epoch 141. Train Loss: 0.006875488, Test Loss : 0.012718789\n",
      "Epoch 142. Train Loss: 0.0060294196, Test Loss : 0.016393138\n",
      "Epoch 143. Train Loss: 0.010271238, Test Loss : 0.023323426\n",
      "Epoch 144. Train Loss: 0.01619331, Test Loss : 0.050086312\n",
      "Epoch 145. Train Loss: 0.011739443, Test Loss : 0.021402927\n",
      "Epoch 146. Train Loss: 0.01100282, Test Loss : 0.020613968\n",
      "Epoch 147. Train Loss: 0.008918939, Test Loss : 0.020859709\n",
      "Epoch 148. Train Loss: 0.010389572, Test Loss : 0.028555084\n",
      "Epoch 149. Train Loss: 0.011765933, Test Loss : 0.021521244\n",
      "\u001b[91m☒\u001b[0m 2004-November-20 Sat = 11/20/2004, sunday(11/20/2004, saturday) 0\n",
      "\u001b[91m☒\u001b[0m 2007-October-31 Wed = 10/13/2007, wednesday(10/31/2007, wednesday) 0\n",
      "\u001b[92m☑\u001b[0m 2001-December-05 Wed = 12/05/2001, wednesday(12/05/2001, wednesday) 1\n",
      "\u001b[91m☒\u001b[0m 2005-April-13 Wed = 04/13/2015, wednesday(04/13/2005, wednesday) 0\n",
      "\u001b[92m☑\u001b[0m 2012-April-08 Sun = 04/08/2012, sunday(04/08/2012, sunday) 1\n",
      "\u001b[91m☒\u001b[0m 2002-January-12 Sat = 01/21/2012, saturday(01/12/2002, saturday) 0\n",
      "\u001b[92m☑\u001b[0m 2007-September-04 Tue = 09/04/2007, tuesday(09/04/2007, tuesday) 1\n",
      "\u001b[92m☑\u001b[0m 2004-October-14 Thu = 10/14/2004, thursday(10/14/2004, thursday) 1\n",
      "\u001b[92m☑\u001b[0m 2003-January-27 Mon = 01/27/2003, monday(01/27/2003, monday) 1\n",
      "\u001b[91m☒\u001b[0m 2007-July-12 Thu = 07/21/2012, thursday(07/12/2007, thursday) 0\n",
      "Epoch 150. Train Loss: 0.025954187, Test Loss : 0.074820735\n",
      "Epoch 151. Train Loss: 0.031844825, Test Loss : 0.038960293\n",
      "Epoch 152. Train Loss: 0.009759944, Test Loss : 0.011991251\n",
      "Epoch 153. Train Loss: 0.005904791, Test Loss : 0.016985692\n",
      "Epoch 154. Train Loss: 0.008104745, Test Loss : 0.011137271\n",
      "Epoch 155. Train Loss: 0.007963382, Test Loss : 0.016961757\n",
      "Epoch 156. Train Loss: 0.005767391, Test Loss : 0.011100803\n",
      "Epoch 157. Train Loss: 0.0052864226, Test Loss : 0.013376143\n",
      "Epoch 158. Train Loss: 0.007728626, Test Loss : 0.03934801\n",
      "Epoch 159. Train Loss: 0.015361956, Test Loss : 0.0132462345\n",
      "\u001b[91m☒\u001b[0m 2005-August-31 Wed = 08/13/2005, wednesday(08/31/2005, wednesday) 0\n",
      "\u001b[92m☑\u001b[0m 2008-February-16 Sat = 02/16/2008, saturday(02/16/2008, saturday) 1\n",
      "\u001b[92m☑\u001b[0m 2004-September-24 Fri = 09/24/2004, friday(09/24/2004, friday) 1\n",
      "\u001b[91m☒\u001b[0m 2002-August-30 Fri = 08/03/2002, friday(08/30/2002, friday) 0\n",
      "\u001b[92m☑\u001b[0m 2004-April-22 Thu = 04/22/2004, thursday(04/22/2004, thursday) 1\n",
      "\u001b[92m☑\u001b[0m 2012-April-03 Tue = 04/03/2012, tuesday(04/03/2012, tuesday) 1\n",
      "\u001b[92m☑\u001b[0m 2005-July-01 Fri = 07/01/2005, friday(07/01/2005, friday) 1\n",
      "\u001b[92m☑\u001b[0m 2010-October-26 Tue = 10/26/2010, tuesday(10/26/2010, tuesday) 1\n",
      "\u001b[92m☑\u001b[0m 2011-August-02 Tue = 08/02/2011, tuesday(08/02/2011, tuesday) 1\n",
      "\u001b[91m☒\u001b[0m 2006-November-07 Tue = 11/07/2016, tuesday(11/07/2006, tuesday) 0\n",
      "Epoch 160. Train Loss: 0.012060024, Test Loss : 0.016697591\n",
      "Epoch 161. Train Loss: 0.01086056, Test Loss : 0.039562885\n",
      "Epoch 162. Train Loss: 0.017239261, Test Loss : 0.03224362\n",
      "Epoch 163. Train Loss: 0.008810628, Test Loss : 0.014055479\n",
      "Epoch 164. Train Loss: 0.0073628016, Test Loss : 0.009864727\n",
      "Epoch 165. Train Loss: 0.006130889, Test Loss : 0.018186435\n",
      "Epoch 166. Train Loss: 0.006114642, Test Loss : 0.015194931\n",
      "Epoch 167. Train Loss: 0.0071786055, Test Loss : 0.018879421\n",
      "Epoch 168. Train Loss: 0.011653336, Test Loss : 0.030323248\n",
      "Epoch 169. Train Loss: 0.016456485, Test Loss : 0.0352863\n",
      "\u001b[92m☑\u001b[0m 2004-April-11 Sun = 04/11/2004, sunday(04/11/2004, sunday) 1\n",
      "\u001b[92m☑\u001b[0m 2003-May-28 Wed = 05/28/2003, wednesday(05/28/2003, wednesday) 1\n",
      "\u001b[92m☑\u001b[0m 2008-March-10 Mon = 03/10/2008, monday(03/10/2008, monday) 1\n",
      "\u001b[92m☑\u001b[0m 2004-September-02 Thu = 09/02/2004, thursday(09/02/2004, thursday) 1\n",
      "\u001b[91m☒\u001b[0m 2008-December-21 Sun = 12/12/2008, sunday(12/21/2008, sunday) 0\n",
      "\u001b[91m☒\u001b[0m 2009-October-12 Mon = 10/11/2009, monday(10/12/2009, monday) 0\n",
      "\u001b[92m☑\u001b[0m 2007-May-14 Mon = 05/14/2007, monday(05/14/2007, monday) 1\n",
      "\u001b[91m☒\u001b[0m 2001-December-27 Thu = 12/27/2010, thursday(12/27/2001, thursday) 0\n",
      "\u001b[92m☑\u001b[0m 2002-June-15 Sat = 06/15/2002, saturday(06/15/2002, saturday) 1\n",
      "\u001b[92m☑\u001b[0m 2002-December-22 Sun = 12/22/2002, sunday(12/22/2002, sunday) 1\n",
      "Epoch 170. Train Loss: 0.008751903, Test Loss : 0.034570385\n",
      "Epoch 171. Train Loss: 0.014417287, Test Loss : 0.036531948\n",
      "Epoch 172. Train Loss: 0.01728021, Test Loss : 0.07286943\n",
      "Epoch 173. Train Loss: 0.031953566, Test Loss : 0.030035123\n",
      "Epoch 174. Train Loss: 0.008552737, Test Loss : 0.008897168\n",
      "Epoch 175. Train Loss: 0.0038845176, Test Loss : 0.009569423\n",
      "Epoch 176. Train Loss: 0.0041587898, Test Loss : 0.01789624\n",
      "Epoch 177. Train Loss: 0.004122304, Test Loss : 0.01516727\n",
      "Epoch 178. Train Loss: 0.0056303786, Test Loss : 0.008737221\n",
      "Epoch 179. Train Loss: 0.0046805236, Test Loss : 0.012201237\n",
      "\u001b[91m☒\u001b[0m 2012-June-08 Fri = 06/08/2002, friday(06/08/2012, friday) 0\n",
      "\u001b[92m☑\u001b[0m 2007-December-05 Wed = 12/05/2007, wednesday(12/05/2007, wednesday) 1\n",
      "\u001b[92m☑\u001b[0m 2002-April-02 Tue = 04/02/2002, tuesday(04/02/2002, tuesday) 1\n",
      "\u001b[91m☒\u001b[0m 2009-December-10 Thu = 12/01/2009, thursday(12/10/2009, thursday) 0\n",
      "\u001b[92m☑\u001b[0m 2001-November-17 Sat = 11/17/2001, saturday(11/17/2001, saturday) 1\n",
      "\u001b[91m☒\u001b[0m 2010-May-03 Mon = 05/03/2002, monday(05/03/2010, monday) 0\n",
      "\u001b[91m☒\u001b[0m 2012-August-30 Thu = 08/30/2002, thursday(08/30/2012, thursday) 0\n",
      "\u001b[91m☒\u001b[0m 2009-January-11 Sun = 01/11/2009, saturday(01/11/2009, sunday) 0\n",
      "\u001b[92m☑\u001b[0m 2002-December-27 Fri = 12/27/2002, friday(12/27/2002, friday) 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m☑\u001b[0m 2006-December-30 Sat = 12/30/2006, saturday(12/30/2006, saturday) 1\n",
      "Epoch 180. Train Loss: 0.014953371, Test Loss : 0.05807786\n",
      "Epoch 181. Train Loss: 0.033897232, Test Loss : 0.036367293\n",
      "Epoch 182. Train Loss: 0.013127927, Test Loss : 0.010891207\n",
      "Epoch 183. Train Loss: 0.004557118, Test Loss : 0.015040576\n",
      "Epoch 184. Train Loss: 0.0053404933, Test Loss : 0.0112009505\n",
      "Epoch 185. Train Loss: 0.0041974215, Test Loss : 0.008689307\n",
      "Epoch 186. Train Loss: 0.0036418831, Test Loss : 0.006495669\n",
      "Epoch 187. Train Loss: 0.004631174, Test Loss : 0.011193379\n",
      "Epoch 188. Train Loss: 0.0059058927, Test Loss : 0.0111832805\n",
      "Epoch 189. Train Loss: 0.0045019733, Test Loss : 0.008001109\n",
      "\u001b[91m☒\u001b[0m 2010-January-05 Tue = 01/05/2001, tuesday(01/05/2010, tuesday) 0\n",
      "\u001b[92m☑\u001b[0m 2003-November-25 Tue = 11/25/2003, tuesday(11/25/2003, tuesday) 1\n",
      "\u001b[91m☒\u001b[0m 2011-October-19 Wed = 10/19/2010, wednesday(10/19/2011, wednesday) 0\n",
      "\u001b[92m☑\u001b[0m 2009-January-29 Thu = 01/29/2009, thursday(01/29/2009, thursday) 1\n",
      "\u001b[92m☑\u001b[0m 2005-February-15 Tue = 02/15/2005, tuesday(02/15/2005, tuesday) 1\n",
      "\u001b[92m☑\u001b[0m 2002-November-08 Fri = 11/08/2002, friday(11/08/2002, friday) 1\n",
      "\u001b[91m☒\u001b[0m 2005-December-17 Sat = 12/15/2007, saturday(12/17/2005, saturday) 0\n",
      "\u001b[92m☑\u001b[0m 2003-November-22 Sat = 11/22/2003, saturday(11/22/2003, saturday) 1\n",
      "\u001b[91m☒\u001b[0m 2011-September-17 Sat = 09/17/2010, saturday(09/17/2011, saturday) 0\n",
      "\u001b[91m☒\u001b[0m 2001-October-18 Thu = 10/18/2008, thursday(10/18/2001, thursday) 0\n",
      "Epoch 190. Train Loss: 0.017075958, Test Loss : 0.03448332\n",
      "Epoch 191. Train Loss: 0.01196583, Test Loss : 0.0062166844\n",
      "Epoch 192. Train Loss: 0.0030886843, Test Loss : 0.0064575947\n",
      "Epoch 193. Train Loss: 0.0030194102, Test Loss : 0.0075144605\n",
      "Epoch 194. Train Loss: 0.0025441104, Test Loss : 0.009682206\n",
      "Epoch 195. Train Loss: 0.004328626, Test Loss : 0.01313769\n",
      "Epoch 196. Train Loss: 0.006753483, Test Loss : 0.028328953\n",
      "Epoch 197. Train Loss: 0.011375499, Test Loss : 0.07113227\n",
      "Epoch 198. Train Loss: 0.061340712, Test Loss : 0.13616164\n",
      "Epoch 199. Train Loss: 0.017564584, Test Loss : 0.011520153\n",
      "\u001b[92m☑\u001b[0m 2008-July-30 Wed = 07/30/2008, wednesday(07/30/2008, wednesday) 1\n",
      "\u001b[92m☑\u001b[0m 2008-August-16 Sat = 08/16/2008, saturday(08/16/2008, saturday) 1\n",
      "\u001b[92m☑\u001b[0m 2010-November-22 Mon = 11/22/2010, monday(11/22/2010, monday) 1\n",
      "\u001b[92m☑\u001b[0m 2008-December-21 Sun = 12/21/2008, sunday(12/21/2008, sunday) 1\n",
      "\u001b[92m☑\u001b[0m 2012-September-01 Sat = 09/01/2012, saturday(09/01/2012, saturday) 1\n",
      "\u001b[92m☑\u001b[0m 2002-October-03 Thu = 10/03/2002, thursday(10/03/2002, thursday) 1\n",
      "\u001b[92m☑\u001b[0m 2006-February-23 Thu = 02/23/2006, thursday(02/23/2006, thursday) 1\n",
      "\u001b[92m☑\u001b[0m 2007-April-30 Mon = 04/30/2007, monday(04/30/2007, monday) 1\n",
      "\u001b[92m☑\u001b[0m 2012-May-05 Sat = 05/05/2012, saturday(05/05/2012, saturday) 1\n",
      "\u001b[92m☑\u001b[0m 2008-May-16 Fri = 05/16/2008, friday(05/16/2008, friday) 1\n",
      "Epoch 200. Train Loss: 0.0028118964, Test Loss : 0.00809072\n",
      "Epoch 201. Train Loss: 0.0028270157, Test Loss : 0.007570884\n",
      "Epoch 202. Train Loss: 0.003016885, Test Loss : 0.014440635\n",
      "Epoch 203. Train Loss: 0.004340375, Test Loss : 0.018152619\n",
      "Epoch 204. Train Loss: 0.007951095, Test Loss : 0.009465527\n",
      "Epoch 205. Train Loss: 0.0022695288, Test Loss : 0.008461123\n",
      "Epoch 206. Train Loss: 0.0022435116, Test Loss : 0.007865433\n",
      "Epoch 207. Train Loss: 0.007397716, Test Loss : 0.021662965\n",
      "Epoch 208. Train Loss: 0.007945269, Test Loss : 0.026307274\n",
      "Epoch 209. Train Loss: 0.009486137, Test Loss : 0.01881513\n",
      "\u001b[92m☑\u001b[0m 2011-March-09 Wed = 03/09/2011, wednesday(03/09/2011, wednesday) 1\n",
      "\u001b[92m☑\u001b[0m 2003-December-18 Thu = 12/18/2003, thursday(12/18/2003, thursday) 1\n",
      "\u001b[91m☒\u001b[0m 2010-December-26 Sun = 12/26/2011, sunday(12/26/2010, sunday) 0\n",
      "\u001b[92m☑\u001b[0m 2002-October-11 Fri = 10/11/2002, friday(10/11/2002, friday) 1\n",
      "\u001b[92m☑\u001b[0m 2009-August-08 Sat = 08/08/2009, saturday(08/08/2009, saturday) 1\n",
      "\u001b[92m☑\u001b[0m 2010-May-03 Mon = 05/03/2010, monday(05/03/2010, monday) 1\n",
      "\u001b[92m☑\u001b[0m 2008-March-11 Tue = 03/11/2008, tuesday(03/11/2008, tuesday) 1\n",
      "\u001b[92m☑\u001b[0m 2006-October-05 Thu = 10/05/2006, thursday(10/05/2006, thursday) 1\n",
      "\u001b[91m☒\u001b[0m 2002-April-20 Sat = 04/02/2002, saturday(04/20/2002, saturday) 0\n",
      "\u001b[92m☑\u001b[0m 2009-May-22 Fri = 05/22/2009, friday(05/22/2009, friday) 1\n",
      "Epoch 210. Train Loss: 0.0067511615, Test Loss : 0.016266353\n",
      "Epoch 211. Train Loss: 0.021297516, Test Loss : 0.101132154\n",
      "Epoch 212. Train Loss: 0.050696258, Test Loss : 0.02443166\n",
      "Epoch 213. Train Loss: 0.0033697472, Test Loss : 0.008282557\n",
      "Epoch 214. Train Loss: 0.0022189594, Test Loss : 0.006913307\n",
      "Epoch 215. Train Loss: 0.002101369, Test Loss : 0.0063124467\n",
      "Epoch 216. Train Loss: 0.002123692, Test Loss : 0.0057709343\n",
      "Epoch 217. Train Loss: 0.0026104772, Test Loss : 0.0055656107\n",
      "Epoch 218. Train Loss: 0.0022218507, Test Loss : 0.017726867\n",
      "Epoch 219. Train Loss: 0.007353798, Test Loss : 0.010070497\n",
      "\u001b[92m☑\u001b[0m 2001-September-12 Wed = 09/12/2001, wednesday(09/12/2001, wednesday) 1\n",
      "\u001b[92m☑\u001b[0m 2002-December-14 Sat = 12/14/2002, saturday(12/14/2002, saturday) 1\n",
      "\u001b[92m☑\u001b[0m 2008-December-16 Tue = 12/16/2008, tuesday(12/16/2008, tuesday) 1\n",
      "\u001b[92m☑\u001b[0m 2010-April-08 Thu = 04/08/2010, thursday(04/08/2010, thursday) 1\n",
      "\u001b[92m☑\u001b[0m 2004-March-05 Fri = 03/05/2004, friday(03/05/2004, friday) 1\n",
      "\u001b[92m☑\u001b[0m 2003-February-28 Fri = 02/28/2003, friday(02/28/2003, friday) 1\n",
      "\u001b[92m☑\u001b[0m 2011-November-24 Thu = 11/24/2011, thursday(11/24/2011, thursday) 1\n",
      "\u001b[92m☑\u001b[0m 2011-August-05 Fri = 08/05/2011, friday(08/05/2011, friday) 1\n",
      "\u001b[91m☒\u001b[0m 2008-July-02 Wed = 07/20/2008, wednesday(07/02/2008, wednesday) 0\n",
      "\u001b[92m☑\u001b[0m 2009-July-07 Tue = 07/07/2009, tuesday(07/07/2009, tuesday) 1\n",
      "Epoch 220. Train Loss: 0.0034306585, Test Loss : 0.007478065\n",
      "Epoch 221. Train Loss: 0.0018305513, Test Loss : 0.005758008\n",
      "Epoch 222. Train Loss: 0.0010266654, Test Loss : 0.0054585855\n",
      "Epoch 223. Train Loss: 0.0011554786, Test Loss : 0.01000925\n",
      "Epoch 224. Train Loss: 0.01626688, Test Loss : 0.10177112\n",
      "Epoch 225. Train Loss: 0.03798031, Test Loss : 0.052758876\n",
      "Epoch 226. Train Loss: 0.0059950934, Test Loss : 0.00971838\n",
      "Epoch 227. Train Loss: 0.0020646218, Test Loss : 0.0072901207\n",
      "Epoch 228. Train Loss: 0.001410081, Test Loss : 0.004580925\n",
      "Epoch 229. Train Loss: 0.0013502645, Test Loss : 0.006016953\n",
      "\u001b[92m☑\u001b[0m 2012-August-28 Tue = 08/28/2012, tuesday(08/28/2012, tuesday) 1\n",
      "\u001b[92m☑\u001b[0m 2010-May-06 Thu = 05/06/2010, thursday(05/06/2010, thursday) 1\n",
      "\u001b[92m☑\u001b[0m 2009-November-16 Mon = 11/16/2009, monday(11/16/2009, monday) 1\n",
      "\u001b[92m☑\u001b[0m 2001-December-05 Wed = 12/05/2001, wednesday(12/05/2001, wednesday) 1\n",
      "\u001b[92m☑\u001b[0m 2007-March-24 Sat = 03/24/2007, saturday(03/24/2007, saturday) 1\n",
      "\u001b[92m☑\u001b[0m 2010-September-16 Thu = 09/16/2010, thursday(09/16/2010, thursday) 1\n",
      "\u001b[92m☑\u001b[0m 2009-November-08 Sun = 11/08/2009, sunday(11/08/2009, sunday) 1\n",
      "\u001b[92m☑\u001b[0m 2011-November-18 Fri = 11/18/2011, friday(11/18/2011, friday) 1\n",
      "\u001b[92m☑\u001b[0m 2011-June-22 Wed = 06/22/2011, wednesday(06/22/2011, wednesday) 1\n",
      "\u001b[92m☑\u001b[0m 2004-June-05 Sat = 06/05/2004, saturday(06/05/2004, saturday) 1\n",
      "Epoch 230. Train Loss: 0.0013126832, Test Loss : 0.0062864567\n",
      "Epoch 231. Train Loss: 0.0013351284, Test Loss : 0.0064850966\n",
      "Epoch 232. Train Loss: 0.01359703, Test Loss : 0.045941938\n",
      "Epoch 233. Train Loss: 0.0089522945, Test Loss : 0.010334057\n",
      "Epoch 234. Train Loss: 0.0052201436, Test Loss : 0.016348377\n",
      "Epoch 235. Train Loss: 0.002850818, Test Loss : 0.004798084\n",
      "Epoch 236. Train Loss: 0.0011953026, Test Loss : 0.0102829505\n",
      "Epoch 237. Train Loss: 0.001230527, Test Loss : 0.006072048\n",
      "Epoch 238. Train Loss: 0.0014737644, Test Loss : 0.007902658\n",
      "Epoch 239. Train Loss: 0.002372142, Test Loss : 0.013734765\n",
      "\u001b[92m☑\u001b[0m 2007-May-22 Tue = 05/22/2007, tuesday(05/22/2007, tuesday) 1\n",
      "\u001b[91m☒\u001b[0m 2010-March-31 Wed = 03/13/2010, wednesday(03/31/2010, wednesday) 0\n",
      "\u001b[92m☑\u001b[0m 2004-March-18 Thu = 03/18/2004, thursday(03/18/2004, thursday) 1\n",
      "\u001b[92m☑\u001b[0m 2001-December-27 Thu = 12/27/2001, thursday(12/27/2001, thursday) 1\n",
      "\u001b[92m☑\u001b[0m 2003-November-06 Thu = 11/06/2003, thursday(11/06/2003, thursday) 1\n",
      "\u001b[92m☑\u001b[0m 2010-May-02 Sun = 05/02/2010, sunday(05/02/2010, sunday) 1\n",
      "\u001b[92m☑\u001b[0m 2011-May-12 Thu = 05/12/2011, thursday(05/12/2011, thursday) 1\n",
      "\u001b[92m☑\u001b[0m 2002-March-23 Sat = 03/23/2002, saturday(03/23/2002, saturday) 1\n",
      "\u001b[92m☑\u001b[0m 2006-February-28 Tue = 02/28/2006, tuesday(02/28/2006, tuesday) 1\n",
      "\u001b[92m☑\u001b[0m 2006-December-24 Sun = 12/24/2006, sunday(12/24/2006, sunday) 1\n",
      "Epoch 240. Train Loss: 0.009144862, Test Loss : 0.02610734\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 241. Train Loss: 0.009422766, Test Loss : 0.027770197\n",
      "Epoch 242. Train Loss: 0.0031580268, Test Loss : 0.006229451\n",
      "Epoch 243. Train Loss: 0.0012251027, Test Loss : 0.004645655\n",
      "Epoch 244. Train Loss: 0.00096410327, Test Loss : 0.0047550728\n",
      "Epoch 245. Train Loss: 0.00080906897, Test Loss : 0.003954032\n",
      "Epoch 246. Train Loss: 0.0007885324, Test Loss : 0.007586718\n",
      "Epoch 247. Train Loss: 0.009319402, Test Loss : 0.08680626\n",
      "Epoch 248. Train Loss: 0.046422333, Test Loss : 0.046591856\n",
      "Epoch 249. Train Loss: 0.005201166, Test Loss : 0.005431755\n",
      "\u001b[92m☑\u001b[0m 2005-February-18 Fri = 02/18/2005, friday(02/18/2005, friday) 1\n",
      "\u001b[92m☑\u001b[0m 2005-December-24 Sat = 12/24/2005, saturday(12/24/2005, saturday) 1\n",
      "\u001b[92m☑\u001b[0m 2003-August-28 Thu = 08/28/2003, thursday(08/28/2003, thursday) 1\n",
      "\u001b[92m☑\u001b[0m 2007-March-12 Mon = 03/12/2007, monday(03/12/2007, monday) 1\n",
      "\u001b[92m☑\u001b[0m 2010-November-11 Thu = 11/11/2010, thursday(11/11/2010, thursday) 1\n",
      "\u001b[92m☑\u001b[0m 2002-April-15 Mon = 04/15/2002, monday(04/15/2002, monday) 1\n",
      "\u001b[92m☑\u001b[0m 2011-March-14 Mon = 03/14/2011, monday(03/14/2011, monday) 1\n",
      "\u001b[92m☑\u001b[0m 2003-October-25 Sat = 10/25/2003, saturday(10/25/2003, saturday) 1\n",
      "\u001b[92m☑\u001b[0m 2010-November-16 Tue = 11/16/2010, tuesday(11/16/2010, tuesday) 1\n",
      "\u001b[92m☑\u001b[0m 2012-September-18 Tue = 09/18/2012, tuesday(09/18/2012, tuesday) 1\n",
      "Epoch 250. Train Loss: 0.0018619506, Test Loss : 0.0044217915\n",
      "Epoch 251. Train Loss: 0.0016184459, Test Loss : 0.005140068\n",
      "Epoch 252. Train Loss: 0.001328469, Test Loss : 0.0028137648\n",
      "Epoch 253. Train Loss: 0.0010125685, Test Loss : 0.0047743083\n",
      "Epoch 254. Train Loss: 0.00097552454, Test Loss : 0.002870229\n",
      "Epoch 255. Train Loss: 0.00093233306, Test Loss : 0.0033202653\n",
      "Epoch 256. Train Loss: 0.0009175646, Test Loss : 0.0029609236\n",
      "Epoch 257. Train Loss: 0.0015304682, Test Loss : 0.010815745\n",
      "Epoch 258. Train Loss: 0.0068263924, Test Loss : 0.11056515\n",
      "Epoch 259. Train Loss: 0.025200032, Test Loss : 0.1184071\n",
      "\u001b[92m☑\u001b[0m 2008-April-25 Fri = 04/25/2008, friday(04/25/2008, friday) 1\n",
      "\u001b[92m☑\u001b[0m 2010-December-28 Tue = 12/28/2010, tuesday(12/28/2010, tuesday) 1\n",
      "\u001b[92m☑\u001b[0m 2009-June-09 Tue = 06/09/2009, tuesday(06/09/2009, tuesday) 1\n",
      "\u001b[92m☑\u001b[0m 2007-February-15 Thu = 02/15/2007, thursday(02/15/2007, thursday) 1\n",
      "\u001b[92m☑\u001b[0m 2008-July-20 Sun = 07/20/2008, sunday(07/20/2008, sunday) 1\n",
      "\u001b[91m☒\u001b[0m 2010-March-12 Fri = 03/21/2010, friday(03/12/2010, friday) 0\n",
      "\u001b[92m☑\u001b[0m 2005-August-16 Tue = 08/16/2005, tuesday(08/16/2005, tuesday) 1\n",
      "\u001b[92m☑\u001b[0m 2005-January-08 Sat = 01/08/2005, saturday(01/08/2005, saturday) 1\n",
      "\u001b[92m☑\u001b[0m 2009-December-22 Tue = 12/22/2009, tuesday(12/22/2009, tuesday) 1\n",
      "\u001b[92m☑\u001b[0m 2009-June-25 Thu = 06/25/2009, thursday(06/25/2009, thursday) 1\n",
      "Epoch 260. Train Loss: 0.037309855, Test Loss : 0.018528027\n",
      "Epoch 261. Train Loss: 0.0018753498, Test Loss : 0.006684929\n",
      "Epoch 262. Train Loss: 0.0012002409, Test Loss : 0.0046650805\n",
      "Epoch 263. Train Loss: 0.0009266161, Test Loss : 0.0038229646\n",
      "Epoch 264. Train Loss: 0.00090087357, Test Loss : 0.0041032354\n",
      "Epoch 265. Train Loss: 0.0008163026, Test Loss : 0.0033654983\n",
      "Epoch 266. Train Loss: 0.00078782265, Test Loss : 0.0025734561\n",
      "Epoch 267. Train Loss: 0.0007963768, Test Loss : 0.0035357336\n",
      "Epoch 268. Train Loss: 0.0007132373, Test Loss : 0.0030819026\n",
      "Epoch 269. Train Loss: 0.00080355076, Test Loss : 0.003665411\n",
      "\u001b[92m☑\u001b[0m 2004-March-20 Sat = 03/20/2004, saturday(03/20/2004, saturday) 1\n",
      "\u001b[92m☑\u001b[0m 2007-September-24 Mon = 09/24/2007, monday(09/24/2007, monday) 1\n",
      "\u001b[92m☑\u001b[0m 2007-March-07 Wed = 03/07/2007, wednesday(03/07/2007, wednesday) 1\n",
      "\u001b[92m☑\u001b[0m 2003-March-08 Sat = 03/08/2003, saturday(03/08/2003, saturday) 1\n",
      "\u001b[92m☑\u001b[0m 2003-March-21 Fri = 03/21/2003, friday(03/21/2003, friday) 1\n",
      "\u001b[92m☑\u001b[0m 2009-August-17 Mon = 08/17/2009, monday(08/17/2009, monday) 1\n",
      "\u001b[92m☑\u001b[0m 2002-September-18 Wed = 09/18/2002, wednesday(09/18/2002, wednesday) 1\n",
      "\u001b[92m☑\u001b[0m 2003-February-23 Sun = 02/23/2003, sunday(02/23/2003, sunday) 1\n",
      "\u001b[92m☑\u001b[0m 2009-March-30 Mon = 03/30/2009, monday(03/30/2009, monday) 1\n",
      "\u001b[92m☑\u001b[0m 2011-July-06 Wed = 07/06/2011, wednesday(07/06/2011, wednesday) 1\n",
      "Epoch 270. Train Loss: 0.0008217356, Test Loss : 0.003517518\n",
      "Epoch 271. Train Loss: 0.00060958124, Test Loss : 0.0025540597\n"
     ]
    }
   ],
   "source": [
    "res = train(model, tr_data_iterator, te_data_iterator \\\n",
    "          , trainer, loss, char_indices, indices_char\n",
    "          , epochs= 300, ctx = ctx, output_file_name = '../models/format_tranlator_{}'.format(datetime.now().strftime('%Y%m%d')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input: 2005-May-14 Sat, length: 15\n",
      "prediction: 05/14/2005, saturday, length:20\n",
      "attention shape= (20, 32)\n",
      "check attn = [0.99999994 1.         1.         1.         1.         1.\n",
      " 1.         0.99999994 1.0000001  1.         1.         1.0000001\n",
      " 1.         1.         1.         0.99999994 1.0000001  1.0000001\n",
      " 0.9999999  1.        ]\n",
      "val shape= (20, 15)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "example = [gen_date() for _ in range(1)]\n",
    "plot_attention(model, example, char_indices, indices_char, in_seq_len)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
